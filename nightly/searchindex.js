Search.setIndex({"docnames": ["bibliography", "index", "reference/abc", "reference/all", "reference/classes", "reference/data", "reference/enums", "reference/functions", "reference/generated/abc/fairseq2.gang.Gang", "reference/generated/abc/fairseq2.nn.PositionEncoder", "reference/generated/abc/fairseq2.nn.Projection", "reference/generated/abc/fairseq2.nn.transformer.AttentionMaskGenerator", "reference/generated/abc/fairseq2.nn.transformer.AttentionWeightHook", "reference/generated/abc/fairseq2.nn.transformer.FeedForwardNetwork", "reference/generated/abc/fairseq2.nn.transformer.MultiheadAttention", "reference/generated/abc/fairseq2.nn.transformer.SDPA", "reference/generated/abc/fairseq2.nn.transformer.TransformerDecoder", "reference/generated/abc/fairseq2.nn.transformer.TransformerDecoderLayer", "reference/generated/abc/fairseq2.nn.transformer.TransformerEncoder", "reference/generated/abc/fairseq2.nn.transformer.TransformerEncoderLayer", "reference/generated/classes/fairseq2.nn.Embedding", "reference/generated/classes/fairseq2.nn.IncrementalState", "reference/generated/classes/fairseq2.nn.IncrementalStateBag", "reference/generated/classes/fairseq2.nn.LearnedPositionEncoder", "reference/generated/classes/fairseq2.nn.Linear", "reference/generated/classes/fairseq2.nn.ModuleList", "reference/generated/classes/fairseq2.nn.RotaryEncoder", "reference/generated/classes/fairseq2.nn.SinusoidalPositionEncoder", "reference/generated/classes/fairseq2.nn.TiedProjection", "reference/generated/classes/fairseq2.nn.transformer.ALiBiAttentionMaskGenerator", "reference/generated/classes/fairseq2.nn.transformer.CausalAttentionMaskGenerator", "reference/generated/classes/fairseq2.nn.transformer.MultiheadAttentionState", "reference/generated/classes/fairseq2.nn.transformer.RelativePositionSDPA", "reference/generated/classes/fairseq2.nn.transformer.StandardFeedForwardNetwork", "reference/generated/classes/fairseq2.nn.transformer.StandardMultiheadAttention", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerDecoder", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerDecoderLayer", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerEncoder", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerEncoderLayer", "reference/generated/classes/fairseq2.nn.transformer.StoreAttentionWeights", "reference/generated/classes/fairseq2.optim.lr_scheduler.CosineAnnealingLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.LRSchedulerBase", "reference/generated/classes/fairseq2.optim.lr_scheduler.MyleLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.NoamLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.PolynomialDecayLR", "reference/generated/data/fairseq2.data.ByteStreamError", "reference/generated/data/fairseq2.data.CString", "reference/generated/data/fairseq2.data.CollateOptionsOverride", "reference/generated/data/fairseq2.data.Collater", "reference/generated/data/fairseq2.data.DataPipeline", "reference/generated/data/fairseq2.data.DataPipelineBuilder", "reference/generated/data/fairseq2.data.DataPipelineError", "reference/generated/data/fairseq2.data.FileMapper", "reference/generated/data/fairseq2.data.PathLike", "reference/generated/data/fairseq2.data.RecordError", "reference/generated/data/fairseq2.data.StringLike", "reference/generated/data/fairseq2.data.VocabularyInfo", "reference/generated/data/fairseq2.data.get_last_failed_example", "reference/generated/data/fairseq2.data.is_string_like", "reference/generated/data/fairseq2.data.list_files", "reference/generated/data/fairseq2.data.read_sequence", "reference/generated/data/fairseq2.data.read_zipped_records", "reference/generated/data/fairseq2.data.text.read_text", "reference/generated/data_text/fairseq2.data.text.LineEnding", "reference/generated/data_text/fairseq2.data.text.MultilingualTextTokenizer", "reference/generated/data_text/fairseq2.data.text.SentencePieceDecoder", "reference/generated/data_text/fairseq2.data.text.SentencePieceEncoder", "reference/generated/data_text/fairseq2.data.text.SentencePieceModel", "reference/generated/data_text/fairseq2.data.text.StrSplitter", "reference/generated/data_text/fairseq2.data.text.StrToIntConverter", "reference/generated/data_text/fairseq2.data.text.StrToTensorConverter", "reference/generated/data_text/fairseq2.data.text.TextTokenDecoder", "reference/generated/data_text/fairseq2.data.text.TextTokenEncoder", "reference/generated/data_text/fairseq2.data.text.TextTokenizer", "reference/generated/data_text/fairseq2.data.text.vocabulary_from_sentencepiece", "reference/generated/enums/fairseq2.nn.transformer.TransformerNormOrder", "reference/generated/functions/fairseq2.nn.utils.mask.to_float_mask", "reference/generated/functions/fairseq2.nn.utils.mask.to_padding_mask"], "filenames": ["bibliography.rst", "index.rst", "reference/abc.rst", "reference/all.rst", "reference/classes.rst", "reference/data.rst", "reference/enums.rst", "reference/functions.rst", "reference/generated/abc/fairseq2.gang.Gang.rst", "reference/generated/abc/fairseq2.nn.PositionEncoder.rst", "reference/generated/abc/fairseq2.nn.Projection.rst", "reference/generated/abc/fairseq2.nn.transformer.AttentionMaskGenerator.rst", "reference/generated/abc/fairseq2.nn.transformer.AttentionWeightHook.rst", "reference/generated/abc/fairseq2.nn.transformer.FeedForwardNetwork.rst", "reference/generated/abc/fairseq2.nn.transformer.MultiheadAttention.rst", "reference/generated/abc/fairseq2.nn.transformer.SDPA.rst", "reference/generated/abc/fairseq2.nn.transformer.TransformerDecoder.rst", "reference/generated/abc/fairseq2.nn.transformer.TransformerDecoderLayer.rst", "reference/generated/abc/fairseq2.nn.transformer.TransformerEncoder.rst", "reference/generated/abc/fairseq2.nn.transformer.TransformerEncoderLayer.rst", "reference/generated/classes/fairseq2.nn.Embedding.rst", "reference/generated/classes/fairseq2.nn.IncrementalState.rst", "reference/generated/classes/fairseq2.nn.IncrementalStateBag.rst", "reference/generated/classes/fairseq2.nn.LearnedPositionEncoder.rst", "reference/generated/classes/fairseq2.nn.Linear.rst", "reference/generated/classes/fairseq2.nn.ModuleList.rst", "reference/generated/classes/fairseq2.nn.RotaryEncoder.rst", "reference/generated/classes/fairseq2.nn.SinusoidalPositionEncoder.rst", "reference/generated/classes/fairseq2.nn.TiedProjection.rst", "reference/generated/classes/fairseq2.nn.transformer.ALiBiAttentionMaskGenerator.rst", "reference/generated/classes/fairseq2.nn.transformer.CausalAttentionMaskGenerator.rst", "reference/generated/classes/fairseq2.nn.transformer.MultiheadAttentionState.rst", "reference/generated/classes/fairseq2.nn.transformer.RelativePositionSDPA.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardFeedForwardNetwork.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardMultiheadAttention.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerDecoder.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerDecoderLayer.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerEncoder.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerEncoderLayer.rst", "reference/generated/classes/fairseq2.nn.transformer.StoreAttentionWeights.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.CosineAnnealingLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.LRSchedulerBase.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.MyleLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.NoamLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.PolynomialDecayLR.rst", "reference/generated/data/fairseq2.data.ByteStreamError.rst", "reference/generated/data/fairseq2.data.CString.rst", "reference/generated/data/fairseq2.data.CollateOptionsOverride.rst", "reference/generated/data/fairseq2.data.Collater.rst", "reference/generated/data/fairseq2.data.DataPipeline.rst", "reference/generated/data/fairseq2.data.DataPipelineBuilder.rst", "reference/generated/data/fairseq2.data.DataPipelineError.rst", "reference/generated/data/fairseq2.data.FileMapper.rst", "reference/generated/data/fairseq2.data.PathLike.rst", "reference/generated/data/fairseq2.data.RecordError.rst", "reference/generated/data/fairseq2.data.StringLike.rst", "reference/generated/data/fairseq2.data.VocabularyInfo.rst", "reference/generated/data/fairseq2.data.get_last_failed_example.rst", "reference/generated/data/fairseq2.data.is_string_like.rst", "reference/generated/data/fairseq2.data.list_files.rst", "reference/generated/data/fairseq2.data.read_sequence.rst", "reference/generated/data/fairseq2.data.read_zipped_records.rst", "reference/generated/data/fairseq2.data.text.read_text.rst", "reference/generated/data_text/fairseq2.data.text.LineEnding.rst", "reference/generated/data_text/fairseq2.data.text.MultilingualTextTokenizer.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceDecoder.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceEncoder.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceModel.rst", "reference/generated/data_text/fairseq2.data.text.StrSplitter.rst", "reference/generated/data_text/fairseq2.data.text.StrToIntConverter.rst", "reference/generated/data_text/fairseq2.data.text.StrToTensorConverter.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenDecoder.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenEncoder.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenizer.rst", "reference/generated/data_text/fairseq2.data.text.vocabulary_from_sentencepiece.rst", "reference/generated/enums/fairseq2.nn.transformer.TransformerNormOrder.rst", "reference/generated/functions/fairseq2.nn.utils.mask.to_float_mask.rst", "reference/generated/functions/fairseq2.nn.utils.mask.to_padding_mask.rst"], "titles": ["Bibliography", "fairseq2 documentation", "ABCs and Protocols", "All", "Classes", "fairseq2.data", "Enums", "Functions", "Gang", "PositionEncoder", "Projection", "AttentionMaskGenerator", "AttentionWeightHook", "FeedForwardNetwork", "MultiheadAttention", "SDPA", "TransformerDecoder", "TransformerDecoderLayer", "TransformerEncoder", "TransformerEncoderLayer", "Embedding", "IncrementalState", "IncrementalStateBag", "LearnedPositionEncoder", "Linear", "ModuleList", "RotaryEncoder", "SinusoidalPositionEncoder", "TiedProjection", "ALiBiAttentionMaskGenerator", "CausalAttentionMaskGenerator", "MultiheadAttentionState", "RelativePositionSDPA", "StandardFeedForwardNetwork", "StandardMultiheadAttention", "StandardTransformerDecoder", "StandardTransformerDecoderLayer", "StandardTransformerEncoder", "StandardTransformerEncoderLayer", "StoreAttentionWeights", "CosineAnnealingLR", "LRSchedulerBase", "MyleLR", "NoamLR", "PolynomialDecayLR", "fairseq2.data.ByteStreamError", "CString", "CollateOptionsOverride", "Collater", "DataPipeline", "DataPipelineBuilder", "fairseq2.data.DataPipelineError", "FileMapper", "PathLike", "fairseq2.data.RecordError", "StringLike", "VocabularyInfo", "get_last_failed_example", "is_string_like", "list_files", "read_sequence", "read_zipped_records", "read_text", "LineEnding", "MultilingualTextTokenizer", "SentencePieceDecoder", "SentencePieceEncoder", "SentencePieceModel", "StrSplitter", "StrToIntConverter", "StrToTensorConverter", "TextTokenDecoder", "TextTokenEncoder", "TextTokenizer", "vocabulary_from_sentencepiece", "TransformerNormOrder", "to_float_mask", "to_padding_mask"], "terms": {"altdj": [0, 34], "23": [0, 34], "joshua": 0, "ainsli": [0, 34], "jame": 0, "lee": 0, "thorp": 0, "michiel": 0, "de": [0, 73], "jong": 0, "yuri": 0, "zemlyanskii": 0, "federico": 0, "lebr\u00f3n": 0, "sumit": 0, "sanghai": 0, "gqa": 0, "train": [0, 1, 20, 25, 40, 42, 43, 44], "gener": [0, 1, 11, 29, 30, 35, 64, 73], "multi": [0, 14, 34, 73], "queri": [0, 14, 15, 32, 34], "transform": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 75], "model": [0, 1, 11, 13, 14, 16, 17, 18, 19, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38, 43, 64, 65, 66, 74], "from": [0, 5, 8, 20, 23, 24, 25, 27, 30, 31, 40, 41, 42, 43, 44, 48, 49, 50, 51, 64, 65, 71], "head": [0, 14, 29, 31, 32, 34], "checkpoint": 0, "2023": 0, "arxiv": 0, "2305": 0, "13245": 0, "dyi": [0, 32], "19": [0, 32], "zihang": 0, "dai": [0, 32], "zhilin": 0, "yang": 0, "yime": 0, "jaim": 0, "carbonel": 0, "quoc": 0, "v": [0, 12, 14, 15, 31, 32, 34], "le": 0, "ruslan": 0, "salakhutdinov": 0, "xl": 0, "attent": [0, 11, 12, 14, 15, 16, 17, 29, 30, 31, 32, 34, 35, 36, 38, 39], "languag": [0, 1, 64, 73], "beyond": 0, "fix": [0, 20, 27, 50], "length": [0, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 48, 77], "context": 0, "2019": 0, "1901": 0, "02860": 0, "fgj19": [0, 35, 37], "angela": 0, "fan": [0, 35, 37], "edouard": 0, "grave": 0, "armand": 0, "joulin": 0, "reduc": [0, 8], "depth": 0, "demand": 0, "structur": 0, "dropout": [0, 15, 32, 33, 36, 38], "url": 0, "http": 0, "org": 0, "ab": 0, "1909": 0, "11556": 0, "doi": 0, "10": [0, 5, 30, 50, 69], "48550": 0, "lh17": [0, 40], "ilya": 0, "loshchilov": [0, 40], "frank": 0, "hutter": [0, 40], "sgdr": 0, "stochast": 0, "gradient": [0, 20], "descent": 0, "warm": 0, "restart": [0, 40], "2017": 0, "1608": 0, "03983": 0, "psl21": [0, 29], "ofir": 0, "press": [0, 29], "noah": 0, "A": [0, 14, 21, 31, 34, 48, 49, 52, 64], "smith": 0, "mike": 0, "lewi": 0, "short": 0, "test": 0, "long": [0, 21, 48], "linear": [0, 10, 28], "bias": 0, "enabl": [0, 50, 52], "input": [0, 5, 8, 9, 10, 15, 20, 21, 23, 24, 26, 27, 28, 32, 48, 68], "extrapol": 0, "2021": 0, "2108": 0, "12409": 0, "swo21": [0, 34, 36, 38, 75], "sam": 0, "shleifer": [0, 34, 36, 38, 75], "jason": 0, "weston": 0, "myle": [0, 42], "ott": [0, 42], "normform": 0, "improv": 0, "pretrain": 0, "extra": [0, 25], "normal": [0, 33, 35, 36, 37, 38, 75], "2110": 0, "09456": 0, "slp": [0, 26], "21": [0, 26], "jianlin": 0, "su": [0, 26], "yu": 0, "lu": 0, "shengfeng": 0, "pan": 0, "ahm": 0, "murtadha": 0, "bo": 0, "wen": 0, "yunfeng": 0, "liu": 0, "roform": 0, "enhanc": 0, "rotari": 0, "posit": [0, 9, 14, 22, 23, 26, 27, 32, 34, 49], "embed": [0, 23], "2104": 0, "09864": 0, "vsp": [0, 27, 33, 34, 35, 36, 37, 38, 43, 75], "17": [0, 27, 33, 34, 35, 36, 37, 38, 43, 75], "ashish": 0, "vaswani": [0, 27, 33, 34, 35, 36, 37, 38, 43, 75], "noam": [0, 42, 43], "shazeer": [0, 43], "niki": 0, "parmar": 0, "jakob": 0, "uszkoreit": 0, "llion": 0, "jone": 0, "aidan": 0, "n": [0, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 77], "gomez": 0, "lukasz": 0, "kaiser": 0, "illia": 0, "polosukhin": 0, "i": [0, 1, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 48, 49, 50, 52, 54, 56, 58, 64, 66, 72, 77], "all": [0, 1, 8, 10, 22, 24, 25, 28, 40, 42, 44, 47, 48, 50, 52, 59, 68], "you": [0, 5, 52], "need": [0, 21, 48], "1706": 0, "03762": 0, "xyh": [0, 75], "20": [0, 75], "ruibin": 0, "xiong": [0, 75], "yunchang": 0, "di": 0, "he": 0, "kai": 0, "zheng": 0, "shuxin": 0, "chen": 0, "xing": 0, "huishuai": 0, "zhang": 0, "yanyan": 0, "lan": 0, "liwei": 0, "wang": 0, "tie": 0, "yan": 0, "On": 0, "layer": [0, 14, 16, 17, 18, 19, 25, 33, 35, 36, 37, 38, 75], "architectur": 0, "2020": 0, "2002": 0, "04745": 0, "sequenc": [1, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 44, 48, 49, 50, 56, 60, 68, 77], "toolkit": 1, "allow": [1, 48, 49], "research": 1, "develop": 1, "custom": 1, "translat": [1, 73], "summar": 1, "other": [1, 5], "content": [1, 52], "task": [1, 64, 73], "data": [1, 10, 24, 28, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], "bibliographi": 1, "provid": [5, 39], "python": [5, 25, 46, 49, 52], "build": 5, "c": 5, "datapipelin": [5, 50], "The": [5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 52, 56, 59, 60, 64, 65, 66, 68, 71, 72, 73, 76, 77], "dataload": [5, 68], "abl": 5, "leverag": 5, "sever": [5, 49, 50, 52], "thread": 5, "work": [5, 8], "around": 5, "global": 5, "interpret": 5, "lock": 5, "limit": 5, "also": [5, 40, 49, 52], "better": 5, "perform": 5, "than": [5, 35, 37, 50], "pure": 5, "look": [5, 52], "like": 5, "thi": [5, 8, 21, 22, 24, 25, 27, 29, 30, 31, 39, 40, 42, 43, 44, 46, 47, 49, 50, 52], "read_text": [5, 68], "file": [5, 45, 52, 59, 61, 62, 64, 68], "tsv": [5, 68], "map": [5, 49, 50, 52, 68], "lambda": [5, 50, 68], "x": [5, 10, 20, 24, 25, 28, 50, 68], "str": [5, 46, 47, 49, 50, 52, 53, 55, 58, 59, 64, 65, 66, 68, 71, 72, 73], "split": [5, 46, 68], "t": [5, 22, 40, 42, 43, 44, 45, 68], "1": [5, 20, 22, 23, 24, 25, 27, 31, 34, 36, 38, 40, 41, 42, 43, 44, 47, 48, 50, 63, 66, 68, 75], "lower": 5, "filter": [5, 50], "len": 5, "function": [5, 39, 50, 68, 69, 70], "item": 5, "go": [5, 68], "through": 5, "pipelin": [5, 49, 50, 51, 62], "don": 5, "have": [5, 48, 49], "flat": 5, "tensor": [5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 48, 64, 65, 66, 70, 71, 72, 73, 76, 77], "can": [5, 14, 34, 45, 49, 50, 52], "tupl": [5, 15, 16, 17, 18, 19, 31, 32, 35, 36, 37, 38, 39, 48], "dictionari": [5, 20, 48, 49, 68], "oper": [5, 8, 49], "specifi": [5, 20, 31, 34, 47, 50, 52, 64, 75], "specif": [5, 11, 48, 73, 77], "notabl": 5, "datapipelinebuild": [5, 49, 59, 60, 61, 62], "ha": [5, 12, 21, 31, 40, 50], "selector": [5, 47, 50], "argument": [5, 73], "choos": 5, "appli": [5, 10, 24, 28, 33, 34, 35, 37, 47, 50, 75], "If": [5, 15, 16, 18, 20, 22, 24, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 48, 49, 50, 59, 64, 73], "3": [5, 23, 25, 27, 30, 43, 48, 50], "select": [5, 21, 31, 50], "third": 5, "foo": 5, "valu": [5, 12, 14, 15, 22, 31, 32, 34, 40, 48, 63, 75], "correspond": [5, 20, 21, 42, 43, 44, 68], "kei": [5, 12, 14, 15, 31, 32, 34, 48, 49, 52], "nest": 5, "separ": [5, 50], "follow": [5, 29, 30, 39, 48, 52, 59], "For": [5, 48, 52], "y": 5, "2": [5, 23, 27, 40, 48, 50, 68, 75], "4": [5, 23, 27, 30, 48], "z": 5, "5": [5, 25, 27, 43, 48, 50], "bar": 5, "6": [5, 27], "refer": [5, 40, 43, 73], "accept": 5, "them": [5, 8, 36, 38, 50], "comma": 5, "list": [5, 25, 46, 48, 50, 59, 64, 65, 68, 71], "exampl": [5, 48, 49, 50, 68], "multipli": [5, 31], "leav": 5, "unmodifi": 5, "helper": 5, "method": [5, 22, 24], "tool": 5, "token": [5, 56, 64, 65, 66, 71, 72, 73], "convert": [5, 68, 76, 77], "byte": [5, 46, 52], "class": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 56, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75], "fairseq2": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "rank": 8, "size": [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 50, 56, 70, 77], "devic": [8, 20, 23, 24, 26, 27, 32, 33, 34, 35, 36, 37, 38, 64, 66, 73], "sourc": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "base": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 56, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75], "abc": [8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 21, 41, 71, 72, 73], "repres": [8, 12, 13, 14, 16, 17, 18, 19, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 56, 64, 73, 77], "set": [8, 22, 25, 34, 64], "process": [8, 17, 19, 36, 38, 50], "collect": 8, "paramet": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 49, 50, 52, 59, 60, 64, 65, 66, 68, 71, 72, 73, 76, 77], "int": [8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 31, 32, 33, 34, 40, 42, 43, 44, 48, 50, 52, 56, 68, 69], "number": [8, 9, 14, 15, 23, 25, 26, 27, 29, 31, 32, 34, 40, 42, 43, 44, 50, 66, 72, 77], "ar": [8, 10, 24, 27, 28, 73], "part": [8, 30, 50], "associ": [8, 40, 42, 43, 44, 73], "abstract": [8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 21, 41, 71, 72, 73], "all_gath": 8, "output_tensor": 8, "input_tensor": 8, "gather": 8, "put": 8, "singl": [8, 48, 50], "output": [8, 10, 16, 17, 18, 19, 21, 24, 28, 33, 34, 35, 36, 37, 38], "accomod": 8, "element": [8, 56, 60, 77], "current": [8, 22, 31, 40, 41, 42, 43, 44, 49, 50], "all_reduc": 8, "op": 8, "across": 8, "reduceoper": 8, "wise": 8, "as_process_group": 8, "return": [8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 48, 49, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "group": [8, 34, 40, 41, 42, 43, 44], "type": [8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 46, 48, 49, 50, 52, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77], "processgroup": 8, "barrier": 8, "synchron": 8, "nn": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 75, 76, 77], "encoding_dim": [9, 23, 26, 27], "max_seq_len": [9, 23, 26, 27], "modul": [9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 63, 75], "encod": [9, 16, 17, 18, 19, 23, 26, 27, 32, 34, 35, 36, 37, 38, 62, 64, 66, 72, 73], "inform": [9, 22, 23, 26, 27, 36, 38, 73, 74], "dimension": [9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 43], "none": [9, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 52, 56, 59, 62, 63, 64, 66, 67, 68, 70, 72, 73, 75, 76, 77], "expect": [9, 22, 23, 26, 27], "maximum": [9, 23, 26, 27], "_do_forward": [9, 26], "seq": [9, 11, 13, 16, 17, 18, 19, 23, 26, 27, 29, 30, 33, 35, 36, 37, 38, 48, 60, 77], "padding_mask": [9, 14, 16, 17, 18, 19, 23, 26, 27, 34, 35, 36, 37, 38], "state_bag": [9, 14, 16, 17, 23, 26, 27, 34, 35, 36], "shape": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 48, 50, 66, 72, 76, 77], "": [9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 46, 49, 50, 58, 66, 68, 69, 70, 72, 75, 77], "e": [9, 20, 22, 23, 26, 27, 31, 34, 40], "where": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 66, 72, 77], "ani": [9, 15, 20, 21, 23, 25, 26, 27, 32, 48, 49, 50, 52, 57, 60, 76, 77], "batch": [9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 47, 48, 50, 77], "dimens": [9, 10, 15, 23, 24, 26, 27, 28, 32, 48, 77], "includ": [9, 15, 23, 26, 27, 32, 44, 77], "float": [9, 14, 15, 16, 17, 18, 19, 23, 25, 26, 27, 31, 32, 33, 34, 35, 36, 37, 38, 40, 42, 44, 49, 76, 77], "pad": [9, 14, 16, 17, 18, 19, 23, 26, 27, 31, 34, 35, 36, 37, 38, 47, 48, 56, 77], "mask": [9, 11, 14, 15, 16, 17, 18, 19, 23, 26, 27, 29, 30, 31, 32, 34, 35, 36, 37, 38, 76, 77], "incrementalstatebag": [9, 14, 16, 17, 23, 26, 27, 34, 35, 36], "state": [9, 14, 16, 17, 21, 22, 23, 26, 27, 31, 34, 35, 36, 40, 41, 42, 43, 44, 49, 50], "bag": [9, 14, 16, 17, 22, 23, 26, 27, 34, 35, 36], "us": [9, 14, 16, 17, 21, 22, 23, 24, 26, 27, 28, 31, 33, 34, 35, 36, 37, 38, 43, 44, 46, 47, 48, 49, 50, 52, 56, 64, 73], "increment": [9, 14, 16, 17, 21, 22, 23, 26, 27, 31, 34, 35, 36], "evalu": [9, 14, 16, 17, 21, 22, 23, 26, 27, 31, 34, 35, 36], "same": [9, 10, 13, 15, 16, 17, 18, 19, 23, 24, 26, 27, 28, 32, 33, 35, 36, 37, 38, 47, 48, 49, 50, 52, 77], "forward": [9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38], "input_dim": [10, 24], "output_dim": [10, 24], "incom": [10, 24, 28], "h_": [10, 24, 28], "inp": [10, 24, 28], "out": [10, 24, 28], "last": [10, 24, 28, 40, 41, 42, 43, 44, 48, 50, 52], "arg": [11, 12, 25, 40, 41, 42, 43, 44], "kwarg": [11, 12], "protocol": [11, 12, 29, 30, 39], "an": [11, 14, 21, 22, 24, 25, 29, 30, 31, 33, 34, 35, 40, 41, 42, 43, 44, 46, 49, 51, 52, 56, 77], "__call__": [11, 12, 29, 30, 39, 48, 52, 65, 66, 68, 69, 70, 71, 72], "which": [11, 14, 22, 27, 29, 30, 34, 39, 40, 41, 42, 43, 44, 64, 73], "m": [11, 12, 13, 14, 16, 17, 18, 19, 22, 23, 27, 29, 30, 33, 34, 35, 36, 37, 38, 39], "implement": [11, 34, 40, 42, 73], "defin": [11, 64], "hook": [12, 14, 34], "pass": [12, 49], "register_attn_weight_hook": [12, 14, 34], "attn": [12, 14, 34, 39], "attn_weight": [12, 14, 34, 39], "multiheadattent": [12, 31, 34, 36, 38], "comput": [12, 14, 15, 17, 31, 32, 34, 36, 40, 41, 42, 43, 44], "weight": [12, 14, 15, 17, 24, 28, 32, 34, 36, 39, 49], "s_": [12, 14, 15, 16, 17, 31, 32, 34, 35, 36], "kv": [12, 14, 15, 32, 34], "model_dim": [13, 14, 16, 17, 18, 19, 32, 33, 34], "feed": [13, 33, 36, 38], "network": [13, 33, 36, 38], "project": [13, 24, 28, 31, 33, 34], "num_head": [14, 29, 32, 34], "_run_attn_weight_hook": [14, 34], "run": [14, 34], "regist": [14, 34], "attn_mask": [14, 34], "key_padding_mask": [14, 31, 34], "k": [14, 15, 24, 31, 32, 34], "ad": [14, 15, 17, 32, 34, 36, 38], "befor": [14, 15, 17, 25, 32, 34, 36, 38, 40], "indic": [14, 20, 34, 65, 66, 68, 71, 72, 73], "ignor": [14, 34], "purpos": [14, 34], "call": [14, 16, 18, 21, 22, 31, 34, 35, 37, 39, 40, 41, 42, 43, 44, 49, 68, 69, 70], "everi": [14, 22, 25, 34, 40, 41, 42, 43, 44, 50, 60], "time": [14, 34, 49, 50], "after": [14, 22, 34, 40, 43, 44, 75], "attentionweighthook": [14, 34, 39], "handl": [14, 34], "remov": [14, 34], "removablehandl": [14, 34], "attn_dropout_p": [15, 32], "0": [15, 20, 23, 25, 27, 30, 32, 33, 35, 36, 37, 38, 40, 42, 44, 48, 50, 66, 68, 75], "scale": [15, 20, 32, 34, 36, 38, 40, 42], "dot": [15, 32, 34], "product": [15, 32, 34], "probabl": [15, 25, 32, 33, 36, 38], "needs_weight": [15, 32], "fals": [15, 20, 24, 32, 34, 36, 38, 40, 41, 42, 43, 44, 48, 49, 50, 62, 64, 65, 66, 68, 73], "bool": [15, 20, 24, 32, 33, 34, 36, 38, 40, 42, 43, 44, 49, 50, 64, 73], "true": [15, 20, 24, 32, 33, 34, 36, 38, 40, 42, 43, 44, 48, 49, 50, 58, 64, 73], "decod": [16, 17, 35, 36, 64, 65, 71, 73], "encoder_output": [16, 17, 35, 36], "encoder_padding_mask": [16, 17, 35, 36], "layer_output_hook": [16, 18, 35, 37], "enc": [16, 17, 35, 36], "m_": [16, 17, 35, 36], "encoder_out": [16, 35], "decoderlayeroutputhook": [16, 35], "each": [16, 18, 35, 37, 40, 42, 43, 44, 48, 49, 50, 61, 75, 77], "stack": [16, 18, 35, 37], "self_attn_mask": [17, 36], "self": [17, 29, 30, 36, 38, 39, 40, 41, 42, 43, 44, 50, 68, 69, 70], "encoderlayeroutputhook": [18, 37], "final": [20, 23, 25, 26, 27, 28, 32, 33, 34, 35, 36, 37, 38, 40, 42, 43, 44, 64, 65, 66, 67], "num_embed": 20, "embedding_dim": 20, "pad_idx": [20, 47, 48, 56], "dtype": [20, 23, 24, 32, 33, 34, 35, 36, 37, 38, 70, 76], "store": [20, 22, 39], "tabl": [20, 32], "entri": [20, 40, 41, 42, 43, 44, 68], "do": 20, "contribut": 20, "therefor": 20, "updat": [20, 40, 42, 43, 44], "dure": [20, 21, 22, 25, 31, 40, 44], "initi": [20, 24, 27, 40, 42, 44], "mathcal": [20, 24], "frac": [20, 24, 27, 40, 42, 43, 44], "text": [20, 24, 27, 40, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], "otherwis": [20, 48], "reset_paramet": [20, 23, 24, 26, 27, 32, 34, 36, 38], "reset": [20, 23, 24, 26, 27, 32, 34, 36, 38, 49], "buffer": [20, 23, 24, 26, 27, 32, 34, 36, 38, 50], "hold": [21, 22, 25, 31], "special": 21, "mode": [21, 64, 73], "onli": [21, 50, 68], "receiv": 21, "previou": 21, "must": [21, 64], "produc": [21, 34], "next": 21, "thu": 21, "cach": [21, 52], "term": 21, "about": [21, 40], "reorder": [21, 22, 31], "new_ord": [21, 22, 31], "rearrang": [21, 31], "accord": [21, 31], "new": [21, 31, 50], "order": [21, 31, 33, 35, 36, 37, 38, 63, 75], "when": [21, 31, 45, 48, 51, 54], "chang": [21, 31], "typic": [21, 31, 73], "case": [21, 31, 50], "beam": [21, 22, 31], "search": [21, 22, 31], "between": [21, 31, 46, 73], "step": [21, 22, 31, 34, 40, 42, 43, 44], "It": [21, 22, 31, 40, 41, 42, 43, 44, 49, 64], "frequent": [21, 31], "torch": [21, 23, 24, 25, 27, 30, 31], "index_select": [21, 31], "object": [22, 29, 30, 39, 40, 41, 42, 43, 44, 46, 47, 48, 50, 52, 56, 67, 68, 69, 70], "get_stat": 22, "kl": 22, "get": [22, 52, 66, 72], "present": 22, "doe": 22, "match": [22, 49, 50, 59, 64], "increment_step": 22, "delta": 22, "should": [22, 31, 40, 41, 42, 43, 44, 47], "g": [22, 30, 31], "keep": [22, 50, 68], "track": 22, "see": [22, 27, 36, 38, 47, 50], "incrementalst": [22, 31], "more": [22, 27, 36, 38, 40, 50, 73], "set_stat": 22, "properti": [22, 49, 66, 72], "positionencod": [23, 26, 27, 34], "learn": [23, 24, 33, 34, 40, 41, 42, 43, 44], "usag": [23, 25, 27, 30, 50, 68], "import": [23, 25, 27, 30], "position_encod": [23, 27], "16": [23, 27], "ones": [23, 27], "1135": 23, "5548": 23, "4293": 23, "0112": 23, "po": [23, 27], "2364": 23, "6009": 23, "3865": 23, "4810": 23, "4746": 23, "4544": 23, "2761": 23, "8828": 23, "grad_fn": 23, "squeezebackward1": 23, "bia": [24, 28, 33, 34], "skip_init": 24, "unless": 24, "overridden": 24, "subclass": [24, 73], "u": [24, 73], "sqrt": [24, 42, 43], "ident": 24, "addit": [24, 33, 34, 40], "left": 24, "uniniti": 24, "becom": 24, "noop": 24, "intend": 24, "author": [24, 43], "who": [24, 50], "want": 24, "differ": [24, 27, 48, 73], "drop_p": 25, "submodul": 25, "extend": [25, 34], "featur": 25, "option": 25, "drop": [25, 50], "random": 25, "iter": [25, 49], "layer1": 25, "layer2": 25, "layer3": 25, "drop_it": 25, "might": 25, "over": [25, 44, 49], "add": 25, "append": [25, 31], "given": [25, 52, 68, 69], "end": [25, 40, 46, 56], "insert": 25, "index": [25, 40, 42, 43, 44, 50, 56, 77], "rel": [26, 32, 40, 52], "describ": [26, 29, 32, 33, 34, 35, 36, 37, 38, 40, 43, 48, 56, 75], "et": [26, 27, 29, 32, 33, 34, 35, 36, 37, 38, 43, 75], "al": [26, 27, 29, 32, 33, 34, 35, 36, 37, 38, 43, 75], "reset_non_persistent_buff": [26, 27], "non": [26, 27, 59], "persist": [26, 27, 49], "_legacy_pad_idx": 27, "sinusoid": 27, "tensor2tensor": 27, "slightli": 27, "descript": 27, "section": [27, 43], "mean": 27, "instead": 27, "pe_": 27, "2i": 27, "sin": 27, "10000": 27, "d_": 27, "co": [27, 40], "we": 27, "geq": 27, "here": 27, "0000e": 27, "00": 27, "9": 27, "4147e": 27, "01": 27, "04": 27, "4030e": 27, "0930e": 27, "02": 27, "1615e": 27, "anoth": 28, "instanc": [28, 35, 50], "share": 28, "attentionmaskgener": [29, 30, 35], "alibi": 29, "h": [29, 31], "causal": 30, "whose": 30, "upper": 30, "triangular": 30, "abov": 30, "main": 30, "diagon": 30, "fill": 30, "neg": 30, "infin": 30, "while": [30, 49, 50, 51, 54, 64, 73], "its": 30, "rest": 30, "zero": [30, 34, 35, 37, 46], "empti": [30, 34, 59], "inf": 30, "bootstrap": 31, "intern": [31, 49], "stp": 31, "k_": 31, "proj": 31, "v_": 31, "cache_reserve_s": 31, "512": 31, "reserv": 31, "capac": 31, "increas": [31, 40, 42, 43, 44, 50], "accumul": 31, "past": 31, "seq_len": [31, 48, 77], "pos_encod": [32, 34], "sdpa": [32, 34], "param": 32, "inner_dim": 33, "inner_activ": 33, "inner_dropout_p": 33, "norm_ord": [33, 35, 36, 37, 38], "transformernormord": [33, 35, 36, 37, 38], "post": [33, 35, 36, 37, 38, 75], "layer_norm_fn": [33, 35, 36, 37, 38], "feedforwardnetwork": [33, 36, 38], "inner": 33, "both": 33, "activ": 33, "relu": 33, "layernormfactori": [33, 35, 36, 37, 38], "factori": [33, 35, 36, 37, 38], "construct": [33, 35, 36, 37, 38, 64, 73], "num_key_value_head": 34, "q_proj": 34, "k_proj": 34, "v_proj": 34, "add_bias_kv": 34, "add_zero_attn": 34, "scale_head": 34, "output_proj": 34, "equival": 34, "standard": 34, "mha": 34, "mqa": 34, "default": [34, 64, 68], "explicitli": 34, "self_attn_mask_gen": 35, "layer_drop_p": [35, 37], "transformerdecod": 35, "modulelist": [35, 37], "causalattentionmaskgener": 35, "greater": [35, 37], "layerdrop": [35, 37], "self_attn": [36, 38], "encoder_decoder_attn": 36, "ffn": [36, 38], "scale_residu": [36, 38], "dropout_p": [36, 38], "transformerdecoderlay": 36, "residu": [36, 38, 75], "transformerencod": 37, "transformerencoderlay": 38, "storag": 39, "mutablesequ": 39, "optim": [40, 41, 42, 43, 44], "lr_schedul": [40, 41, 42, 43, 44], "cycle_len": 40, "num_warmup_step": [40, 42, 43, 44], "cycle_mul": 40, "lr_mul": 40, "start_lr": [40, 42, 44], "final_lr": [40, 44], "last_epoch": [40, 41, 42, 43, 44], "verbos": [40, 41, 42, 43, 44], "lrschedulerbas": [40, 42, 43, 44], "rate": [40, 41, 42, 43, 44], "schedul": [40, 41, 42, 43, 44], "warmup": [40, 42, 43, 44], "eta_t": [40, 42, 43, 44], "eta_": [40, 42, 43, 44], "t_": [40, 42, 43, 44], "pi": 40, "anneal": 40, "cycl": 40, "t_i": 40, "taken": 40, "sinc": 40, "total": [40, 44], "within": 40, "th": 40, "cosin": 40, "effect": 40, "start": [40, 63, 75], "larg": [40, 50], "rapidli": 40, "decreas": [40, 42, 43, 44], "minimum": 40, "being": [40, 49, 50], "again": 40, "pleas": 40, "paper": [40, 43], "detail": [40, 47, 50], "In": [40, 43], "origin": [40, 42, 48], "support": [40, 46, 64], "phase": 40, "linearli": [40, 42, 43, 44], "first": [40, 42, 43, 44, 49, 68], "chainabl": [40, 42, 43, 44], "factor": 40, "grow": 40, "respect": [40, 42, 44], "epoch": [40, 41, 42, 43, 44], "print": [40, 42, 43, 44], "messag": [40, 42, 43, 44], "stdout": [40, 42, 43, 44], "get_last_lr": [40, 41, 42, 43, 44], "load_state_dict": [40, 41, 42, 43, 44, 49], "state_dict": [40, 41, 42, 43, 44, 49, 50], "load": [40, 41, 42, 43, 44, 50], "dict": [40, 41, 42, 43, 44, 48, 49, 52, 68], "print_lr": [40, 41, 42, 43, 44], "is_verbos": [40, 41, 42, 43, 44], "lr": [40, 41, 42, 43, 44], "displai": [40, 41, 42, 43, 44], "contain": [40, 41, 42, 43, 44, 49], "variabl": [40, 41, 42, 43, 44], "__dict__": [40, 41, 42, 43, 44], "_lrschedul": 41, "version": [42, 50], "noamlr": 42, "preserv": [42, 48], "min": [42, 43], "essenti": 42, "squar": [42, 43], "root": [42, 43, 52], "wa": [42, 48], "propos": 42, "fairseq": 42, "under": [42, 59], "name": [42, 49, 52, 63, 68, 75], "inversesquarerootlr": 42, "thereaft": [42, 43, 44], "proportion": [42, 43], "invers": [42, 43], "commonli": 43, "second": [43, 49, 68], "num_step": 44, "power": 44, "polynomi": 44, "decai": 44, "p": 44, "degre": 44, "expon": 44, "except": [45, 51, 54], "rais": [45, 49, 51, 54], "dataset": [45, 54], "read": [45, 49, 50, 51, 52, 54, 60, 61, 62, 68], "immut": 46, "utf": 46, "8": [46, 50], "string": [46, 68], "copi": 46, "marshal": 46, "nativ": [46, 49], "code": 46, "lstrip": 46, "whitespac": 46, "begin": [46, 56, 75], "rstrip": 46, "sep": [46, 68], "word": 46, "delimit": 46, "pad_to_multipl": [47, 48], "overrid": [47, 48], "how": 47, "collat": 47, "creat": [47, 48, 50, 64, 68, 73], "particular": 47, "column": [47, 48, 50, 68], "idx": 47, "multipl": [47, 48], "syntax": [47, 50, 59], "concaten": 48, "requir": 48, "made": 48, "enough": 48, "fit": 48, "longest": 48, "round": [48, 49], "up": [48, 52], "is_rag": 48, "shortest": 48, "alwai": 48, "collateoptionsoverrid": 48, "disk": 49, "resum": 49, "later": 49, "still": 49, "segfault": 49, "wors": 49, "__iter__": [49, 63, 75], "modifi": 49, "so": [49, 52], "safe": 49, "strict": [49, 50], "restor": [49, 50], "previous": 49, "enforc": [49, 52], "move": 49, "back": [49, 64], "static": 49, "round_robin": 49, "extract": 49, "robin": 49, "sampl": [49, 50], "data_pipelin": 49, "desir": 49, "distribut": 49, "uniform": 49, "zip": [49, 61], "zip_to_shortest": 49, "flatten": 49, "disable_parallel": 49, "togeth": 49, "assign": 49, "sequenti": 49, "is_broken": 49, "broken": 49, "futur": 49, "datapipelineerror": 49, "api": 50, "and_return": [50, 68], "max_num_warn": 50, "bucket": 50, "bucket_s": 50, "drop_remaind": 50, "combin": 50, "consecut": 50, "fewer": 50, "bucket_by_length": 50, "similar": 50, "predic": 50, "those": 50, "callabl": 50, "fn": 50, "num_parallel_cal": 50, "yield": 50, "12": 50, "15": 50, "result": 50, "core": 50, "b": 50, "11": 50, "13": 50, "thei": 50, "automat": 50, "chain": 50, "f1": 50, "f2": 50, "effici": 50, "colum": 50, "parallel": 50, "prefetch": 50, "num_exampl": 50, "background": 50, "shard": 50, "shard_idx": 50, "num_shard": 50, "shuffl": 50, "shuffle_window": 50, "intermedi": 50, "randomli": 50, "replac": 50, "memori": [50, 52, 64, 73], "full": 50, "save": 50, "ensur": 50, "preemption": 50, "lost": 50, "significantli": 50, "disabl": 50, "skip": 50, "take": 50, "most": 50, "yield_from": 50, "error": 51, "occur": 51, "root_dir": 52, "cached_fd_count": 52, "slice": 52, "big_fil": 52, "txt": 52, "1024": 52, "48": 52, "offset": 52, "cstring": [52, 53, 55, 58, 59, 64, 65, 66, 68, 71, 72], "o": [52, 53, 59, 64], "pathlik": [52, 59, 64], "directori": 52, "warn": 52, "happili": 52, "system": 52, "lru": 52, "especi": 52, "filenam": 52, "pars": [52, 69], "path": [52, 59], "memoryblock": 52, "block": 52, "regular": 52, "filemapperoutput": 52, "alia": [53, 55], "union": [53, 55], "corrupt": 54, "record": 54, "encount": 54, "unk_idx": 56, "bos_idx": 56, "eos_idx": 56, "vocabulari": [56, 73, 74], "symbol": 56, "unknown": 56, "typeguard": 58, "pathnam": [59, 61, 62, 64, 67], "pattern": 59, "recurs": 59, "travers": 59, "fnmatch": 59, "archiv": 61, "line_end": 62, "lineend": 62, "infer": 62, "ltrim": 62, "rtrim": 62, "skip_empti": 62, "memory_map": 62, "block_siz": 62, "open": 62, "line": 62, "one": [62, 68], "qualnam": [63, 75], "boundari": [63, 75], "enum": [63, 75], "classmethod": [63, 75], "member": [63, 75], "definit": [63, 75], "source_lang": 64, "target_lang": 64, "default_source_lang": 64, "default_target_lang": 64, "texttoken": 64, "bilingu": 64, "multilingu": [64, 73], "sentencepiec": 64, "user": 64, "valid": [64, 73], "create_encod": [64, 73], "target": [64, 73], "fall": 64, "create_decod": [64, 73], "texttokendecod": [64, 65, 73], "lang": [64, 73], "pin_memori": [64, 66, 73], "either": 64, "depend": 64, "pin": [64, 73], "texttokenencod": [64, 66, 73], "revers": [65, 66], "token_indic": [65, 71], "prefix_token": 66, "suffix_token": 66, "enable_sampl": 66, "nbest_siz": 66, "alpha": 66, "sentenc": [66, 71, 72, 73], "prefix_indic": [66, 72], "prefix": [66, 72], "suffix_indic": [66, 72], "suffix": [66, 72], "control_symbol": 67, "exclud": 68, "charact": 68, "tab": 68, "Will": 68, "per": 68, "va": 68, "cc": 68, "BY": 68, "franc": 68, "tatoeba": 68, "en": [68, 73], "fr": 68, "integ": 69, "vocab_info": 73, "vocabularyinfo": [73, 74], "concret": 73, "job": 73, "distinguish": 73, "transcript": 73, "connect": 75, "pre": 75, "pre_with_normform": 75, "util": [76, 77], "boolean": 76, "point": 76, "arrai": 77}, "objects": {"fairseq2.data": [[45, 0, 1, "", "ByteStreamError"], [46, 1, 1, "", "CString"], [47, 1, 1, "", "CollateOptionsOverride"], [48, 1, 1, "", "Collater"], [49, 1, 1, "", "DataPipeline"], [50, 1, 1, "", "DataPipelineBuilder"], [51, 0, 1, "", "DataPipelineError"], [52, 1, 1, "", "FileMapper"], [53, 4, 1, "", "PathLike"], [54, 0, 1, "", "RecordError"], [55, 4, 1, "", "StringLike"], [56, 1, 1, "", "VocabularyInfo"], [57, 6, 1, "", "get_last_failed_example"], [58, 6, 1, "", "is_string_like"], [59, 6, 1, "", "list_files"], [60, 6, 1, "", "read_sequence"], [61, 6, 1, "", "read_zipped_records"]], "fairseq2.data.CString": [[46, 2, 1, "", "bytes"], [46, 2, 1, "", "lstrip"], [46, 2, 1, "", "rstrip"], [46, 2, 1, "", "split"]], "fairseq2.data.Collater": [[48, 2, 1, "", "__call__"]], "fairseq2.data.DataPipeline": [[49, 2, 1, "", "__iter__"], [49, 3, 1, "", "is_broken"], [49, 2, 1, "", "load_state_dict"], [49, 2, 1, "", "reset"], [49, 2, 1, "", "round_robin"], [49, 2, 1, "", "sample"], [49, 2, 1, "", "state_dict"], [49, 2, 1, "", "zip"]], "fairseq2.data.DataPipelineBuilder": [[50, 2, 1, "", "and_return"], [50, 2, 1, "", "bucket"], [50, 2, 1, "", "bucket_by_length"], [50, 2, 1, "", "filter"], [50, 2, 1, "", "map"], [50, 2, 1, "", "prefetch"], [50, 2, 1, "", "shard"], [50, 2, 1, "", "shuffle"], [50, 2, 1, "", "skip"], [50, 2, 1, "", "take"], [50, 2, 1, "", "yield_from"]], "fairseq2.data.FileMapper": [[52, 2, 1, "", "__call__"]], "fairseq2.data.VocabularyInfo": [[56, 5, 1, "", "bos_idx"], [56, 5, 1, "", "eos_idx"], [56, 5, 1, "", "pad_idx"], [56, 5, 1, "", "size"], [56, 5, 1, "", "unk_idx"]], "fairseq2.data.text": [[63, 1, 1, "", "LineEnding"], [64, 1, 1, "", "MultilingualTextTokenizer"], [65, 1, 1, "", "SentencePieceDecoder"], [66, 1, 1, "", "SentencePieceEncoder"], [67, 1, 1, "", "SentencePieceModel"], [68, 1, 1, "", "StrSplitter"], [69, 1, 1, "", "StrToIntConverter"], [70, 1, 1, "", "StrToTensorConverter"], [71, 1, 1, "", "TextTokenDecoder"], [72, 1, 1, "", "TextTokenEncoder"], [73, 1, 1, "", "TextTokenizer"], [62, 6, 1, "", "read_text"], [74, 6, 1, "", "vocabulary_from_sentencepiece"]], "fairseq2.data.text.LineEnding": [[63, 2, 1, "", "__iter__"]], "fairseq2.data.text.MultilingualTextTokenizer": [[64, 2, 1, "", "create_decoder"], [64, 2, 1, "", "create_encoder"]], "fairseq2.data.text.SentencePieceDecoder": [[65, 2, 1, "", "__call__"]], "fairseq2.data.text.SentencePieceEncoder": [[66, 2, 1, "", "__call__"], [66, 3, 1, "", "prefix_indices"], [66, 3, 1, "", "suffix_indices"]], "fairseq2.data.text.StrSplitter": [[68, 2, 1, "", "__call__"]], "fairseq2.data.text.StrToIntConverter": [[69, 2, 1, "", "__call__"]], "fairseq2.data.text.StrToTensorConverter": [[70, 2, 1, "", "__call__"]], "fairseq2.data.text.TextTokenDecoder": [[71, 2, 1, "", "__call__"]], "fairseq2.data.text.TextTokenEncoder": [[72, 2, 1, "", "__call__"], [72, 3, 1, "", "prefix_indices"], [72, 3, 1, "", "suffix_indices"]], "fairseq2.data.text.TextTokenizer": [[73, 2, 1, "", "create_decoder"], [73, 2, 1, "", "create_encoder"]], "fairseq2.gang": [[8, 1, 1, "", "Gang"]], "fairseq2.gang.Gang": [[8, 2, 1, "", "all_gather"], [8, 2, 1, "", "all_reduce"], [8, 2, 1, "", "as_process_group"], [8, 2, 1, "", "barrier"]], "fairseq2.nn": [[20, 1, 1, "", "Embedding"], [21, 1, 1, "", "IncrementalState"], [22, 1, 1, "", "IncrementalStateBag"], [23, 1, 1, "", "LearnedPositionEncoder"], [24, 1, 1, "", "Linear"], [25, 1, 1, "", "ModuleList"], [9, 1, 1, "", "PositionEncoder"], [10, 1, 1, "", "Projection"], [26, 1, 1, "", "RotaryEncoder"], [27, 1, 1, "", "SinusoidalPositionEncoder"], [28, 1, 1, "", "TiedProjection"]], "fairseq2.nn.Embedding": [[20, 2, 1, "", "forward"], [20, 2, 1, "", "reset_parameters"]], "fairseq2.nn.IncrementalState": [[21, 2, 1, "", "reorder"]], "fairseq2.nn.IncrementalStateBag": [[22, 2, 1, "", "get_state"], [22, 2, 1, "", "increment_step"], [22, 2, 1, "", "reorder"], [22, 2, 1, "", "set_state"], [22, 3, 1, "", "step"]], "fairseq2.nn.LearnedPositionEncoder": [[23, 2, 1, "", "forward"], [23, 2, 1, "", "reset_parameters"]], "fairseq2.nn.Linear": [[24, 2, 1, "", "forward"], [24, 2, 1, "", "reset_parameters"]], "fairseq2.nn.ModuleList": [[25, 2, 1, "", "append"], [25, 2, 1, "", "drop_iter"], [25, 2, 1, "", "extend"], [25, 2, 1, "", "insert"]], "fairseq2.nn.PositionEncoder": [[9, 2, 1, "", "_do_forward"], [9, 2, 1, "", "forward"]], "fairseq2.nn.Projection": [[10, 2, 1, "", "forward"]], "fairseq2.nn.RotaryEncoder": [[26, 2, 1, "", "_do_forward"], [26, 2, 1, "", "forward"], [26, 2, 1, "", "reset_non_persistent_buffers"], [26, 2, 1, "", "reset_parameters"]], "fairseq2.nn.SinusoidalPositionEncoder": [[27, 2, 1, "", "forward"], [27, 2, 1, "", "reset_non_persistent_buffers"], [27, 2, 1, "", "reset_parameters"]], "fairseq2.nn.TiedProjection": [[28, 2, 1, "", "forward"]], "fairseq2.nn.transformer": [[29, 1, 1, "", "ALiBiAttentionMaskGenerator"], [11, 1, 1, "", "AttentionMaskGenerator"], [12, 1, 1, "", "AttentionWeightHook"], [30, 1, 1, "", "CausalAttentionMaskGenerator"], [13, 1, 1, "", "FeedForwardNetwork"], [14, 1, 1, "", "MultiheadAttention"], [31, 1, 1, "", "MultiheadAttentionState"], [32, 1, 1, "", "RelativePositionSDPA"], [15, 1, 1, "", "SDPA"], [33, 1, 1, "", "StandardFeedForwardNetwork"], [34, 1, 1, "", "StandardMultiheadAttention"], [35, 1, 1, "", "StandardTransformerDecoder"], [36, 1, 1, "", "StandardTransformerDecoderLayer"], [37, 1, 1, "", "StandardTransformerEncoder"], [38, 1, 1, "", "StandardTransformerEncoderLayer"], [39, 1, 1, "", "StoreAttentionWeights"], [16, 1, 1, "", "TransformerDecoder"], [17, 1, 1, "", "TransformerDecoderLayer"], [18, 1, 1, "", "TransformerEncoder"], [19, 1, 1, "", "TransformerEncoderLayer"], [75, 1, 1, "", "TransformerNormOrder"]], "fairseq2.nn.transformer.ALiBiAttentionMaskGenerator": [[29, 2, 1, "", "__call__"]], "fairseq2.nn.transformer.AttentionMaskGenerator": [[11, 2, 1, "", "__call__"]], "fairseq2.nn.transformer.AttentionWeightHook": [[12, 2, 1, "", "__call__"]], "fairseq2.nn.transformer.CausalAttentionMaskGenerator": [[30, 2, 1, "", "__call__"]], "fairseq2.nn.transformer.FeedForwardNetwork": [[13, 2, 1, "", "forward"]], "fairseq2.nn.transformer.MultiheadAttention": [[14, 2, 1, "", "_run_attn_weight_hooks"], [14, 2, 1, "", "forward"], [14, 2, 1, "", "register_attn_weight_hook"]], "fairseq2.nn.transformer.MultiheadAttentionState": [[31, 2, 1, "", "append"], [31, 5, 1, "", "cache_reserve_size"], [31, 5, 1, "", "k"], [31, 5, 1, "", "key_padding_mask"], [31, 2, 1, "", "reorder"], [31, 5, 1, "", "seq_len"], [31, 5, 1, "", "v"]], "fairseq2.nn.transformer.RelativePositionSDPA": [[32, 2, 1, "", "forward"], [32, 2, 1, "", "reset_parameters"]], "fairseq2.nn.transformer.SDPA": [[15, 2, 1, "", "forward"]], "fairseq2.nn.transformer.StandardFeedForwardNetwork": [[33, 2, 1, "", "forward"]], "fairseq2.nn.transformer.StandardMultiheadAttention": [[34, 2, 1, "", "_run_attn_weight_hooks"], [34, 2, 1, "", "forward"], [34, 2, 1, "", "register_attn_weight_hook"], [34, 2, 1, "", "reset_parameters"]], "fairseq2.nn.transformer.StandardTransformerDecoder": [[35, 2, 1, "", "forward"]], "fairseq2.nn.transformer.StandardTransformerDecoderLayer": [[36, 2, 1, "", "forward"], [36, 2, 1, "", "reset_parameters"]], "fairseq2.nn.transformer.StandardTransformerEncoder": [[37, 2, 1, "", "forward"]], "fairseq2.nn.transformer.StandardTransformerEncoderLayer": [[38, 2, 1, "", "forward"], [38, 2, 1, "", "reset_parameters"]], "fairseq2.nn.transformer.StoreAttentionWeights": [[39, 2, 1, "", "__call__"]], "fairseq2.nn.transformer.TransformerDecoder": [[16, 2, 1, "", "forward"]], "fairseq2.nn.transformer.TransformerDecoderLayer": [[17, 2, 1, "", "forward"]], "fairseq2.nn.transformer.TransformerEncoder": [[18, 2, 1, "", "forward"]], "fairseq2.nn.transformer.TransformerEncoderLayer": [[19, 2, 1, "", "forward"]], "fairseq2.nn.transformer.TransformerNormOrder": [[75, 5, 1, "", "POST"], [75, 5, 1, "", "PRE"], [75, 5, 1, "", "PRE_WITH_NORMFORMER"], [75, 2, 1, "", "__iter__"]], "fairseq2.nn.utils.mask": [[76, 6, 1, "", "to_float_mask"], [77, 6, 1, "", "to_padding_mask"]], "fairseq2.optim.lr_scheduler": [[40, 1, 1, "", "CosineAnnealingLR"], [41, 1, 1, "", "LRSchedulerBase"], [42, 1, 1, "", "MyleLR"], [43, 1, 1, "", "NoamLR"], [44, 1, 1, "", "PolynomialDecayLR"]], "fairseq2.optim.lr_scheduler.CosineAnnealingLR": [[40, 2, 1, "", "get_last_lr"], [40, 2, 1, "", "load_state_dict"], [40, 2, 1, "", "print_lr"], [40, 2, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.LRSchedulerBase": [[41, 2, 1, "", "get_last_lr"], [41, 2, 1, "", "load_state_dict"], [41, 2, 1, "", "print_lr"], [41, 2, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.MyleLR": [[42, 2, 1, "", "get_last_lr"], [42, 2, 1, "", "load_state_dict"], [42, 2, 1, "", "print_lr"], [42, 2, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.NoamLR": [[43, 2, 1, "", "get_last_lr"], [43, 2, 1, "", "load_state_dict"], [43, 2, 1, "", "print_lr"], [43, 2, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.PolynomialDecayLR": [[44, 2, 1, "", "get_last_lr"], [44, 2, 1, "", "load_state_dict"], [44, 2, 1, "", "print_lr"], [44, 2, 1, "", "state_dict"]]}, "objtypes": {"0": "py:exception", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:data", "5": "py:attribute", "6": "py:function"}, "objnames": {"0": ["py", "exception", "Python exception"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "data", "Python data"], "5": ["py", "attribute", "Python attribute"], "6": ["py", "function", "Python function"]}, "titleterms": {"bibliographi": 0, "fairseq2": [1, 5, 45, 51, 54], "document": 1, "refer": 1, "misc": 1, "abc": [2, 3], "protocol": [2, 3], "all": 3, "class": [3, 4, 5], "enum": [3, 6], "function": [3, 7], "data": [5, 45, 51, 54], "column": 5, "syntax": 5, "public": 5, "us": 5, "api": 5, "text": 5, "gang": 8, "positionencod": 9, "project": 10, "attentionmaskgener": 11, "attentionweighthook": 12, "feedforwardnetwork": 13, "multiheadattent": 14, "sdpa": 15, "transformerdecod": 16, "transformerdecoderlay": 17, "transformerencod": 18, "transformerencoderlay": 19, "embed": 20, "incrementalst": 21, "incrementalstatebag": 22, "learnedpositionencod": 23, "linear": 24, "modulelist": 25, "rotaryencod": 26, "sinusoidalpositionencod": 27, "tiedproject": 28, "alibiattentionmaskgener": 29, "causalattentionmaskgener": 30, "multiheadattentionst": 31, "relativepositionsdpa": 32, "standardfeedforwardnetwork": 33, "standardmultiheadattent": 34, "standardtransformerdecod": 35, "standardtransformerdecoderlay": 36, "standardtransformerencod": 37, "standardtransformerencoderlay": 38, "storeattentionweight": 39, "cosineannealinglr": 40, "lrschedulerbas": 41, "mylelr": 42, "noamlr": 43, "polynomialdecaylr": 44, "bytestreamerror": 45, "cstring": 46, "collateoptionsoverrid": 47, "collat": 48, "datapipelin": 49, "datapipelinebuild": 50, "datapipelineerror": 51, "filemapp": 52, "pathlik": 53, "recorderror": 54, "stringlik": 55, "vocabularyinfo": 56, "get_last_failed_exampl": 57, "is_string_lik": 58, "list_fil": 59, "read_sequ": 60, "read_zipped_record": 61, "read_text": 62, "lineend": 63, "multilingualtexttoken": 64, "sentencepiecedecod": 65, "sentencepieceencod": 66, "sentencepiecemodel": 67, "strsplitter": 68, "strtointconvert": 69, "strtotensorconvert": 70, "texttokendecod": 71, "texttokenencod": 72, "texttoken": 73, "vocabulary_from_sentencepiec": 74, "transformernormord": 75, "to_float_mask": 76, "to_padding_mask": 77}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9, "sphinx": 57}, "alltitles": {"Bibliography": [[0, "bibliography"]], "fairseq2 documentation": [[1, "fairseq2-documentation"]], "fairseq2 Reference": [[1, null]], "Misc": [[1, null]], "ABCs and Protocols": [[2, "abcs-and-protocols"], [3, "abcs-and-protocols"]], "All": [[3, "all"]], "Classes": [[3, "classes"], [4, "classes"]], "Enums": [[3, "enums"], [6, "enums"]], "Functions": [[3, "functions"], [7, "functions"]], "fairseq2.data": [[5, "fairseq2-data"]], "Column syntax": [[5, "column-syntax"]], "Public classes used in fairseq2 API:": [[5, "public-classes-used-in-fairseq2-api"]], "fairseq2.data.text": [[5, "fairseq2-data-text"]], "Gang": [[8, "gang"]], "PositionEncoder": [[9, "positionencoder"]], "Projection": [[10, "projection"]], "AttentionMaskGenerator": [[11, "attentionmaskgenerator"]], "AttentionWeightHook": [[12, "attentionweighthook"]], "FeedForwardNetwork": [[13, "feedforwardnetwork"]], "MultiheadAttention": [[14, "multiheadattention"]], "SDPA": [[15, "sdpa"]], "TransformerDecoder": [[16, "transformerdecoder"]], "TransformerDecoderLayer": [[17, "transformerdecoderlayer"]], "TransformerEncoder": [[18, "transformerencoder"]], "TransformerEncoderLayer": [[19, "transformerencoderlayer"]], "Embedding": [[20, "embedding"]], "IncrementalState": [[21, "incrementalstate"]], "IncrementalStateBag": [[22, "incrementalstatebag"]], "LearnedPositionEncoder": [[23, "learnedpositionencoder"]], "Linear": [[24, "linear"]], "ModuleList": [[25, "modulelist"]], "RotaryEncoder": [[26, "rotaryencoder"]], "SinusoidalPositionEncoder": [[27, "sinusoidalpositionencoder"]], "TiedProjection": [[28, "tiedprojection"]], "ALiBiAttentionMaskGenerator": [[29, "alibiattentionmaskgenerator"]], "CausalAttentionMaskGenerator": [[30, "causalattentionmaskgenerator"]], "MultiheadAttentionState": [[31, "multiheadattentionstate"]], "RelativePositionSDPA": [[32, "relativepositionsdpa"]], "StandardFeedForwardNetwork": [[33, "standardfeedforwardnetwork"]], "StandardMultiheadAttention": [[34, "standardmultiheadattention"]], "StandardTransformerDecoder": [[35, "standardtransformerdecoder"]], "StandardTransformerDecoderLayer": [[36, "standardtransformerdecoderlayer"]], "StandardTransformerEncoder": [[37, "standardtransformerencoder"]], "StandardTransformerEncoderLayer": [[38, "standardtransformerencoderlayer"]], "StoreAttentionWeights": [[39, "storeattentionweights"]], "CosineAnnealingLR": [[40, "cosineannealinglr"]], "LRSchedulerBase": [[41, "lrschedulerbase"]], "MyleLR": [[42, "mylelr"]], "NoamLR": [[43, "noamlr"]], "PolynomialDecayLR": [[44, "polynomialdecaylr"]], "fairseq2.data.ByteStreamError": [[45, "fairseq2-data-bytestreamerror"]], "CString": [[46, "cstring"]], "CollateOptionsOverride": [[47, "collateoptionsoverride"]], "Collater": [[48, "collater"]], "DataPipeline": [[49, "datapipeline"]], "DataPipelineBuilder": [[50, "datapipelinebuilder"]], "fairseq2.data.DataPipelineError": [[51, "fairseq2-data-datapipelineerror"]], "FileMapper": [[52, "filemapper"]], "PathLike": [[53, "pathlike"]], "fairseq2.data.RecordError": [[54, "fairseq2-data-recorderror"]], "StringLike": [[55, "stringlike"]], "VocabularyInfo": [[56, "vocabularyinfo"]], "get_last_failed_example": [[57, "get-last-failed-example"]], "is_string_like": [[58, "is-string-like"]], "list_files": [[59, "list-files"]], "read_sequence": [[60, "read-sequence"]], "read_zipped_records": [[61, "read-zipped-records"]], "read_text": [[62, "read-text"]], "LineEnding": [[63, "lineending"]], "MultilingualTextTokenizer": [[64, "multilingualtexttokenizer"]], "SentencePieceDecoder": [[65, "sentencepiecedecoder"]], "SentencePieceEncoder": [[66, "sentencepieceencoder"]], "SentencePieceModel": [[67, "sentencepiecemodel"]], "StrSplitter": [[68, "strsplitter"]], "StrToIntConverter": [[69, "strtointconverter"]], "StrToTensorConverter": [[70, "strtotensorconverter"]], "TextTokenDecoder": [[71, "texttokendecoder"]], "TextTokenEncoder": [[72, "texttokenencoder"]], "TextTokenizer": [[73, "texttokenizer"]], "vocabulary_from_sentencepiece": [[74, "vocabulary-from-sentencepiece"]], "TransformerNormOrder": [[75, "transformernormorder"]], "to_float_mask": [[76, "to-float-mask"]], "to_padding_mask": [[77, "to-padding-mask"]]}, "indexentries": {"gang (class in fairseq2.gang)": [[8, "fairseq2.gang.Gang"]], "all_gather() (fairseq2.gang.gang method)": [[8, "fairseq2.gang.Gang.all_gather"]], "all_reduce() (fairseq2.gang.gang method)": [[8, "fairseq2.gang.Gang.all_reduce"]], "as_process_group() (fairseq2.gang.gang method)": [[8, "fairseq2.gang.Gang.as_process_group"]], "barrier() (fairseq2.gang.gang method)": [[8, "fairseq2.gang.Gang.barrier"]], "positionencoder (class in fairseq2.nn)": [[9, "fairseq2.nn.PositionEncoder"]], "_do_forward() (fairseq2.nn.positionencoder method)": [[9, "fairseq2.nn.PositionEncoder._do_forward"]], "forward() (fairseq2.nn.positionencoder method)": [[9, "fairseq2.nn.PositionEncoder.forward"]], "projection (class in fairseq2.nn)": [[10, "fairseq2.nn.Projection"]], "forward() (fairseq2.nn.projection method)": [[10, "fairseq2.nn.Projection.forward"]], "attentionmaskgenerator (class in fairseq2.nn.transformer)": [[11, "fairseq2.nn.transformer.AttentionMaskGenerator"]], "__call__() (fairseq2.nn.transformer.attentionmaskgenerator method)": [[11, "fairseq2.nn.transformer.AttentionMaskGenerator.__call__"]], "attentionweighthook (class in fairseq2.nn.transformer)": [[12, "fairseq2.nn.transformer.AttentionWeightHook"]], "__call__() (fairseq2.nn.transformer.attentionweighthook method)": [[12, "fairseq2.nn.transformer.AttentionWeightHook.__call__"]], "feedforwardnetwork (class in fairseq2.nn.transformer)": [[13, "fairseq2.nn.transformer.FeedForwardNetwork"]], "forward() (fairseq2.nn.transformer.feedforwardnetwork method)": [[13, "fairseq2.nn.transformer.FeedForwardNetwork.forward"]], "multiheadattention (class in fairseq2.nn.transformer)": [[14, "fairseq2.nn.transformer.MultiheadAttention"]], "_run_attn_weight_hooks() (fairseq2.nn.transformer.multiheadattention method)": [[14, "fairseq2.nn.transformer.MultiheadAttention._run_attn_weight_hooks"]], "forward() (fairseq2.nn.transformer.multiheadattention method)": [[14, "fairseq2.nn.transformer.MultiheadAttention.forward"]], "register_attn_weight_hook() (fairseq2.nn.transformer.multiheadattention method)": [[14, "fairseq2.nn.transformer.MultiheadAttention.register_attn_weight_hook"]], "sdpa (class in fairseq2.nn.transformer)": [[15, "fairseq2.nn.transformer.SDPA"]], "forward() (fairseq2.nn.transformer.sdpa method)": [[15, "fairseq2.nn.transformer.SDPA.forward"]], "transformerdecoder (class in fairseq2.nn.transformer)": [[16, "fairseq2.nn.transformer.TransformerDecoder"]], "forward() (fairseq2.nn.transformer.transformerdecoder method)": [[16, "fairseq2.nn.transformer.TransformerDecoder.forward"]], "transformerdecoderlayer (class in fairseq2.nn.transformer)": [[17, "fairseq2.nn.transformer.TransformerDecoderLayer"]], "forward() (fairseq2.nn.transformer.transformerdecoderlayer method)": [[17, "fairseq2.nn.transformer.TransformerDecoderLayer.forward"]], "transformerencoder (class in fairseq2.nn.transformer)": [[18, "fairseq2.nn.transformer.TransformerEncoder"]], "forward() (fairseq2.nn.transformer.transformerencoder method)": [[18, "fairseq2.nn.transformer.TransformerEncoder.forward"]], "transformerencoderlayer (class in fairseq2.nn.transformer)": [[19, "fairseq2.nn.transformer.TransformerEncoderLayer"]], "forward() (fairseq2.nn.transformer.transformerencoderlayer method)": [[19, "fairseq2.nn.transformer.TransformerEncoderLayer.forward"]], "embedding (class in fairseq2.nn)": [[20, "fairseq2.nn.Embedding"]], "forward() (fairseq2.nn.embedding method)": [[20, "fairseq2.nn.Embedding.forward"]], "reset_parameters() (fairseq2.nn.embedding method)": [[20, "fairseq2.nn.Embedding.reset_parameters"]], "incrementalstate (class in fairseq2.nn)": [[21, "fairseq2.nn.IncrementalState"]], "reorder() (fairseq2.nn.incrementalstate method)": [[21, "fairseq2.nn.IncrementalState.reorder"]], "incrementalstatebag (class in fairseq2.nn)": [[22, "fairseq2.nn.IncrementalStateBag"]], "get_state() (fairseq2.nn.incrementalstatebag method)": [[22, "fairseq2.nn.IncrementalStateBag.get_state"]], "increment_step() (fairseq2.nn.incrementalstatebag method)": [[22, "fairseq2.nn.IncrementalStateBag.increment_step"]], "reorder() (fairseq2.nn.incrementalstatebag method)": [[22, "fairseq2.nn.IncrementalStateBag.reorder"]], "set_state() (fairseq2.nn.incrementalstatebag method)": [[22, "fairseq2.nn.IncrementalStateBag.set_state"]], "step (fairseq2.nn.incrementalstatebag property)": [[22, "fairseq2.nn.IncrementalStateBag.step"]], "learnedpositionencoder (class in fairseq2.nn)": [[23, "fairseq2.nn.LearnedPositionEncoder"]], "forward() (fairseq2.nn.learnedpositionencoder method)": [[23, "fairseq2.nn.LearnedPositionEncoder.forward"]], "reset_parameters() (fairseq2.nn.learnedpositionencoder method)": [[23, "fairseq2.nn.LearnedPositionEncoder.reset_parameters"]], "linear (class in fairseq2.nn)": [[24, "fairseq2.nn.Linear"]], "forward() (fairseq2.nn.linear method)": [[24, "fairseq2.nn.Linear.forward"]], "reset_parameters() (fairseq2.nn.linear method)": [[24, "fairseq2.nn.Linear.reset_parameters"]], "modulelist (class in fairseq2.nn)": [[25, "fairseq2.nn.ModuleList"]], "append() (fairseq2.nn.modulelist method)": [[25, "fairseq2.nn.ModuleList.append"]], "drop_iter() (fairseq2.nn.modulelist method)": [[25, "fairseq2.nn.ModuleList.drop_iter"]], "extend() (fairseq2.nn.modulelist method)": [[25, "fairseq2.nn.ModuleList.extend"]], "insert() (fairseq2.nn.modulelist method)": [[25, "fairseq2.nn.ModuleList.insert"]], "rotaryencoder (class in fairseq2.nn)": [[26, "fairseq2.nn.RotaryEncoder"]], "_do_forward() (fairseq2.nn.rotaryencoder method)": [[26, "fairseq2.nn.RotaryEncoder._do_forward"]], "forward() (fairseq2.nn.rotaryencoder method)": [[26, "fairseq2.nn.RotaryEncoder.forward"]], "reset_non_persistent_buffers() (fairseq2.nn.rotaryencoder method)": [[26, "fairseq2.nn.RotaryEncoder.reset_non_persistent_buffers"]], "reset_parameters() (fairseq2.nn.rotaryencoder method)": [[26, "fairseq2.nn.RotaryEncoder.reset_parameters"]], "sinusoidalpositionencoder (class in fairseq2.nn)": [[27, "fairseq2.nn.SinusoidalPositionEncoder"]], "forward() (fairseq2.nn.sinusoidalpositionencoder method)": [[27, "fairseq2.nn.SinusoidalPositionEncoder.forward"]], "reset_non_persistent_buffers() (fairseq2.nn.sinusoidalpositionencoder method)": [[27, "fairseq2.nn.SinusoidalPositionEncoder.reset_non_persistent_buffers"]], "reset_parameters() (fairseq2.nn.sinusoidalpositionencoder method)": [[27, "fairseq2.nn.SinusoidalPositionEncoder.reset_parameters"]], "tiedprojection (class in fairseq2.nn)": [[28, "fairseq2.nn.TiedProjection"]], "forward() (fairseq2.nn.tiedprojection method)": [[28, "fairseq2.nn.TiedProjection.forward"]], "alibiattentionmaskgenerator (class in fairseq2.nn.transformer)": [[29, "fairseq2.nn.transformer.ALiBiAttentionMaskGenerator"]], "__call__() (fairseq2.nn.transformer.alibiattentionmaskgenerator method)": [[29, "fairseq2.nn.transformer.ALiBiAttentionMaskGenerator.__call__"]], "causalattentionmaskgenerator (class in fairseq2.nn.transformer)": [[30, "fairseq2.nn.transformer.CausalAttentionMaskGenerator"]], "__call__() (fairseq2.nn.transformer.causalattentionmaskgenerator method)": [[30, "fairseq2.nn.transformer.CausalAttentionMaskGenerator.__call__"]], "multiheadattentionstate (class in fairseq2.nn.transformer)": [[31, "fairseq2.nn.transformer.MultiheadAttentionState"]], "append() (fairseq2.nn.transformer.multiheadattentionstate method)": [[31, "fairseq2.nn.transformer.MultiheadAttentionState.append"]], "cache_reserve_size (fairseq2.nn.transformer.multiheadattentionstate attribute)": [[31, "fairseq2.nn.transformer.MultiheadAttentionState.cache_reserve_size"]], "k (fairseq2.nn.transformer.multiheadattentionstate attribute)": [[31, "fairseq2.nn.transformer.MultiheadAttentionState.k"]], "key_padding_mask (fairseq2.nn.transformer.multiheadattentionstate attribute)": [[31, "fairseq2.nn.transformer.MultiheadAttentionState.key_padding_mask"]], "reorder() (fairseq2.nn.transformer.multiheadattentionstate method)": [[31, "fairseq2.nn.transformer.MultiheadAttentionState.reorder"]], "seq_len (fairseq2.nn.transformer.multiheadattentionstate attribute)": [[31, "fairseq2.nn.transformer.MultiheadAttentionState.seq_len"]], "v (fairseq2.nn.transformer.multiheadattentionstate attribute)": [[31, "fairseq2.nn.transformer.MultiheadAttentionState.v"]], "relativepositionsdpa (class in fairseq2.nn.transformer)": [[32, "fairseq2.nn.transformer.RelativePositionSDPA"]], "forward() (fairseq2.nn.transformer.relativepositionsdpa method)": [[32, "fairseq2.nn.transformer.RelativePositionSDPA.forward"]], "reset_parameters() (fairseq2.nn.transformer.relativepositionsdpa method)": [[32, "fairseq2.nn.transformer.RelativePositionSDPA.reset_parameters"]], "standardfeedforwardnetwork (class in fairseq2.nn.transformer)": [[33, "fairseq2.nn.transformer.StandardFeedForwardNetwork"]], "forward() (fairseq2.nn.transformer.standardfeedforwardnetwork method)": [[33, "fairseq2.nn.transformer.StandardFeedForwardNetwork.forward"]], "standardmultiheadattention (class in fairseq2.nn.transformer)": [[34, "fairseq2.nn.transformer.StandardMultiheadAttention"]], "_run_attn_weight_hooks() (fairseq2.nn.transformer.standardmultiheadattention method)": [[34, "fairseq2.nn.transformer.StandardMultiheadAttention._run_attn_weight_hooks"]], "forward() (fairseq2.nn.transformer.standardmultiheadattention method)": [[34, "fairseq2.nn.transformer.StandardMultiheadAttention.forward"]], "register_attn_weight_hook() (fairseq2.nn.transformer.standardmultiheadattention method)": [[34, "fairseq2.nn.transformer.StandardMultiheadAttention.register_attn_weight_hook"]], "reset_parameters() (fairseq2.nn.transformer.standardmultiheadattention method)": [[34, "fairseq2.nn.transformer.StandardMultiheadAttention.reset_parameters"]], "standardtransformerdecoder (class in fairseq2.nn.transformer)": [[35, "fairseq2.nn.transformer.StandardTransformerDecoder"]], "forward() (fairseq2.nn.transformer.standardtransformerdecoder method)": [[35, "fairseq2.nn.transformer.StandardTransformerDecoder.forward"]], "standardtransformerdecoderlayer (class in fairseq2.nn.transformer)": [[36, "fairseq2.nn.transformer.StandardTransformerDecoderLayer"]], "forward() (fairseq2.nn.transformer.standardtransformerdecoderlayer method)": [[36, "fairseq2.nn.transformer.StandardTransformerDecoderLayer.forward"]], "reset_parameters() (fairseq2.nn.transformer.standardtransformerdecoderlayer method)": [[36, "fairseq2.nn.transformer.StandardTransformerDecoderLayer.reset_parameters"]], "standardtransformerencoder (class in fairseq2.nn.transformer)": [[37, "fairseq2.nn.transformer.StandardTransformerEncoder"]], "forward() (fairseq2.nn.transformer.standardtransformerencoder method)": [[37, "fairseq2.nn.transformer.StandardTransformerEncoder.forward"]], "standardtransformerencoderlayer (class in fairseq2.nn.transformer)": [[38, "fairseq2.nn.transformer.StandardTransformerEncoderLayer"]], "forward() (fairseq2.nn.transformer.standardtransformerencoderlayer method)": [[38, "fairseq2.nn.transformer.StandardTransformerEncoderLayer.forward"]], "reset_parameters() (fairseq2.nn.transformer.standardtransformerencoderlayer method)": [[38, "fairseq2.nn.transformer.StandardTransformerEncoderLayer.reset_parameters"]], "storeattentionweights (class in fairseq2.nn.transformer)": [[39, "fairseq2.nn.transformer.StoreAttentionWeights"]], "__call__() (fairseq2.nn.transformer.storeattentionweights method)": [[39, "fairseq2.nn.transformer.StoreAttentionWeights.__call__"]], "cosineannealinglr (class in fairseq2.optim.lr_scheduler)": [[40, "fairseq2.optim.lr_scheduler.CosineAnnealingLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[40, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[40, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[40, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[40, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.state_dict"]], "lrschedulerbase (class in fairseq2.optim.lr_scheduler)": [[41, "fairseq2.optim.lr_scheduler.LRSchedulerBase"]], "get_last_lr() (fairseq2.optim.lr_scheduler.lrschedulerbase method)": [[41, "fairseq2.optim.lr_scheduler.LRSchedulerBase.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.lrschedulerbase method)": [[41, "fairseq2.optim.lr_scheduler.LRSchedulerBase.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.lrschedulerbase method)": [[41, "fairseq2.optim.lr_scheduler.LRSchedulerBase.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.lrschedulerbase method)": [[41, "fairseq2.optim.lr_scheduler.LRSchedulerBase.state_dict"]], "mylelr (class in fairseq2.optim.lr_scheduler)": [[42, "fairseq2.optim.lr_scheduler.MyleLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.mylelr method)": [[42, "fairseq2.optim.lr_scheduler.MyleLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.mylelr method)": [[42, "fairseq2.optim.lr_scheduler.MyleLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.mylelr method)": [[42, "fairseq2.optim.lr_scheduler.MyleLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.mylelr method)": [[42, "fairseq2.optim.lr_scheduler.MyleLR.state_dict"]], "noamlr (class in fairseq2.optim.lr_scheduler)": [[43, "fairseq2.optim.lr_scheduler.NoamLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.noamlr method)": [[43, "fairseq2.optim.lr_scheduler.NoamLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.noamlr method)": [[43, "fairseq2.optim.lr_scheduler.NoamLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.noamlr method)": [[43, "fairseq2.optim.lr_scheduler.NoamLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.noamlr method)": [[43, "fairseq2.optim.lr_scheduler.NoamLR.state_dict"]], "polynomialdecaylr (class in fairseq2.optim.lr_scheduler)": [[44, "fairseq2.optim.lr_scheduler.PolynomialDecayLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[44, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[44, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[44, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[44, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.state_dict"]], "bytestreamerror": [[45, "fairseq2.data.ByteStreamError"]], "cstring (class in fairseq2.data)": [[46, "fairseq2.data.CString"]], "bytes() (fairseq2.data.cstring method)": [[46, "fairseq2.data.CString.bytes"]], "lstrip() (fairseq2.data.cstring method)": [[46, "fairseq2.data.CString.lstrip"]], "rstrip() (fairseq2.data.cstring method)": [[46, "fairseq2.data.CString.rstrip"]], "split() (fairseq2.data.cstring method)": [[46, "fairseq2.data.CString.split"]], "collateoptionsoverride (class in fairseq2.data)": [[47, "fairseq2.data.CollateOptionsOverride"]], "collater (class in fairseq2.data)": [[48, "fairseq2.data.Collater"]], "__call__() (fairseq2.data.collater method)": [[48, "fairseq2.data.Collater.__call__"]], "datapipeline (class in fairseq2.data)": [[49, "fairseq2.data.DataPipeline"]], "__iter__() (fairseq2.data.datapipeline method)": [[49, "fairseq2.data.DataPipeline.__iter__"]], "is_broken (fairseq2.data.datapipeline property)": [[49, "fairseq2.data.DataPipeline.is_broken"]], "load_state_dict() (fairseq2.data.datapipeline method)": [[49, "fairseq2.data.DataPipeline.load_state_dict"]], "reset() (fairseq2.data.datapipeline method)": [[49, "fairseq2.data.DataPipeline.reset"]], "round_robin() (fairseq2.data.datapipeline static method)": [[49, "fairseq2.data.DataPipeline.round_robin"]], "sample() (fairseq2.data.datapipeline static method)": [[49, "fairseq2.data.DataPipeline.sample"]], "state_dict() (fairseq2.data.datapipeline method)": [[49, "fairseq2.data.DataPipeline.state_dict"]], "zip() (fairseq2.data.datapipeline static method)": [[49, "fairseq2.data.DataPipeline.zip"]], "datapipelinebuilder (class in fairseq2.data)": [[50, "fairseq2.data.DataPipelineBuilder"]], "and_return() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.and_return"]], "bucket() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.bucket"]], "bucket_by_length() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.bucket_by_length"]], "filter() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.filter"]], "map() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.map"]], "prefetch() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.prefetch"]], "shard() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.shard"]], "shuffle() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.shuffle"]], "skip() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.skip"]], "take() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.take"]], "yield_from() (fairseq2.data.datapipelinebuilder method)": [[50, "fairseq2.data.DataPipelineBuilder.yield_from"]], "datapipelineerror": [[51, "fairseq2.data.DataPipelineError"]], "filemapper (class in fairseq2.data)": [[52, "fairseq2.data.FileMapper"]], "__call__() (fairseq2.data.filemapper method)": [[52, "fairseq2.data.FileMapper.__call__"]], "pathlike (in module fairseq2.data)": [[53, "fairseq2.data.PathLike"]], "recorderror": [[54, "fairseq2.data.RecordError"]], "stringlike (in module fairseq2.data)": [[55, "fairseq2.data.StringLike"]], "vocabularyinfo (class in fairseq2.data)": [[56, "fairseq2.data.VocabularyInfo"]], "bos_idx (fairseq2.data.vocabularyinfo attribute)": [[56, "fairseq2.data.VocabularyInfo.bos_idx"]], "eos_idx (fairseq2.data.vocabularyinfo attribute)": [[56, "fairseq2.data.VocabularyInfo.eos_idx"]], "pad_idx (fairseq2.data.vocabularyinfo attribute)": [[56, "fairseq2.data.VocabularyInfo.pad_idx"]], "size (fairseq2.data.vocabularyinfo attribute)": [[56, "fairseq2.data.VocabularyInfo.size"]], "unk_idx (fairseq2.data.vocabularyinfo attribute)": [[56, "fairseq2.data.VocabularyInfo.unk_idx"]], "get_last_failed_example() (in module fairseq2.data)": [[57, "fairseq2.data.get_last_failed_example"]], "is_string_like() (in module fairseq2.data)": [[58, "fairseq2.data.is_string_like"]], "list_files() (in module fairseq2.data)": [[59, "fairseq2.data.list_files"]], "read_sequence() (in module fairseq2.data)": [[60, "fairseq2.data.read_sequence"]], "read_zipped_records() (in module fairseq2.data)": [[61, "fairseq2.data.read_zipped_records"]], "read_text() (in module fairseq2.data.text)": [[62, "fairseq2.data.text.read_text"]], "lineending (class in fairseq2.data.text)": [[63, "fairseq2.data.text.LineEnding"]], "__iter__() (fairseq2.data.text.lineending class method)": [[63, "fairseq2.data.text.LineEnding.__iter__"]], "multilingualtexttokenizer (class in fairseq2.data.text)": [[64, "fairseq2.data.text.MultilingualTextTokenizer"]], "create_decoder() (fairseq2.data.text.multilingualtexttokenizer method)": [[64, "fairseq2.data.text.MultilingualTextTokenizer.create_decoder"]], "create_encoder() (fairseq2.data.text.multilingualtexttokenizer method)": [[64, "fairseq2.data.text.MultilingualTextTokenizer.create_encoder"]], "sentencepiecedecoder (class in fairseq2.data.text)": [[65, "fairseq2.data.text.SentencePieceDecoder"]], "__call__() (fairseq2.data.text.sentencepiecedecoder method)": [[65, "fairseq2.data.text.SentencePieceDecoder.__call__"]], "sentencepieceencoder (class in fairseq2.data.text)": [[66, "fairseq2.data.text.SentencePieceEncoder"]], "__call__() (fairseq2.data.text.sentencepieceencoder method)": [[66, "fairseq2.data.text.SentencePieceEncoder.__call__"]], "prefix_indices (fairseq2.data.text.sentencepieceencoder property)": [[66, "fairseq2.data.text.SentencePieceEncoder.prefix_indices"]], "suffix_indices (fairseq2.data.text.sentencepieceencoder property)": [[66, "fairseq2.data.text.SentencePieceEncoder.suffix_indices"]], "sentencepiecemodel (class in fairseq2.data.text)": [[67, "fairseq2.data.text.SentencePieceModel"]], "strsplitter (class in fairseq2.data.text)": [[68, "fairseq2.data.text.StrSplitter"]], "__call__() (fairseq2.data.text.strsplitter method)": [[68, "fairseq2.data.text.StrSplitter.__call__"]], "strtointconverter (class in fairseq2.data.text)": [[69, "fairseq2.data.text.StrToIntConverter"]], "__call__() (fairseq2.data.text.strtointconverter method)": [[69, "fairseq2.data.text.StrToIntConverter.__call__"]], "strtotensorconverter (class in fairseq2.data.text)": [[70, "fairseq2.data.text.StrToTensorConverter"]], "__call__() (fairseq2.data.text.strtotensorconverter method)": [[70, "fairseq2.data.text.StrToTensorConverter.__call__"]], "texttokendecoder (class in fairseq2.data.text)": [[71, "fairseq2.data.text.TextTokenDecoder"]], "__call__() (fairseq2.data.text.texttokendecoder method)": [[71, "fairseq2.data.text.TextTokenDecoder.__call__"]], "texttokenencoder (class in fairseq2.data.text)": [[72, "fairseq2.data.text.TextTokenEncoder"]], "__call__() (fairseq2.data.text.texttokenencoder method)": [[72, "fairseq2.data.text.TextTokenEncoder.__call__"]], "prefix_indices (fairseq2.data.text.texttokenencoder property)": [[72, "fairseq2.data.text.TextTokenEncoder.prefix_indices"]], "suffix_indices (fairseq2.data.text.texttokenencoder property)": [[72, "fairseq2.data.text.TextTokenEncoder.suffix_indices"]], "texttokenizer (class in fairseq2.data.text)": [[73, "fairseq2.data.text.TextTokenizer"]], "create_decoder() (fairseq2.data.text.texttokenizer method)": [[73, "fairseq2.data.text.TextTokenizer.create_decoder"]], "create_encoder() (fairseq2.data.text.texttokenizer method)": [[73, "fairseq2.data.text.TextTokenizer.create_encoder"]], "vocabulary_from_sentencepiece() (in module fairseq2.data.text)": [[74, "fairseq2.data.text.vocabulary_from_sentencepiece"]], "post (fairseq2.nn.transformer.transformernormorder attribute)": [[75, "fairseq2.nn.transformer.TransformerNormOrder.POST"]], "pre (fairseq2.nn.transformer.transformernormorder attribute)": [[75, "fairseq2.nn.transformer.TransformerNormOrder.PRE"]], "pre_with_normformer (fairseq2.nn.transformer.transformernormorder attribute)": [[75, "fairseq2.nn.transformer.TransformerNormOrder.PRE_WITH_NORMFORMER"]], "transformernormorder (class in fairseq2.nn.transformer)": [[75, "fairseq2.nn.transformer.TransformerNormOrder"]], "__iter__() (fairseq2.nn.transformer.transformernormorder class method)": [[75, "fairseq2.nn.transformer.TransformerNormOrder.__iter__"]], "to_float_mask() (in module fairseq2.nn.utils.mask)": [[76, "fairseq2.nn.utils.mask.to_float_mask"]], "to_padding_mask() (in module fairseq2.nn.utils.mask)": [[77, "fairseq2.nn.utils.mask.to_padding_mask"]]}})