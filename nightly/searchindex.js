Search.setIndex({"docnames": ["bibliography", "index", "reference/abc", "reference/all", "reference/classes", "reference/data", "reference/enums", "reference/functions", "reference/generated/abc/fairseq2.gang.Gang", "reference/generated/abc/fairseq2.nn.PositionEncoder", "reference/generated/abc/fairseq2.nn.Projection", "reference/generated/abc/fairseq2.nn.transformer.AttentionMaskGenerator", "reference/generated/abc/fairseq2.nn.transformer.AttentionWeightHook", "reference/generated/abc/fairseq2.nn.transformer.FeedForwardNetwork", "reference/generated/abc/fairseq2.nn.transformer.MultiheadAttention", "reference/generated/abc/fairseq2.nn.transformer.SDPA", "reference/generated/abc/fairseq2.nn.transformer.TransformerDecoder", "reference/generated/abc/fairseq2.nn.transformer.TransformerDecoderLayer", "reference/generated/abc/fairseq2.nn.transformer.TransformerEncoder", "reference/generated/abc/fairseq2.nn.transformer.TransformerEncoderLayer", "reference/generated/classes/fairseq2.nn.Embedding", "reference/generated/classes/fairseq2.nn.IncrementalState", "reference/generated/classes/fairseq2.nn.IncrementalStateBag", "reference/generated/classes/fairseq2.nn.LearnedPositionEncoder", "reference/generated/classes/fairseq2.nn.Linear", "reference/generated/classes/fairseq2.nn.ModuleList", "reference/generated/classes/fairseq2.nn.RotaryEncoder", "reference/generated/classes/fairseq2.nn.SinusoidalPositionEncoder", "reference/generated/classes/fairseq2.nn.TiedProjection", "reference/generated/classes/fairseq2.nn.transformer.ALiBiAttentionMaskGenerator", "reference/generated/classes/fairseq2.nn.transformer.CausalAttentionMaskGenerator", "reference/generated/classes/fairseq2.nn.transformer.RelativePositionSDPA", "reference/generated/classes/fairseq2.nn.transformer.StandardFeedForwardNetwork", "reference/generated/classes/fairseq2.nn.transformer.StandardMultiheadAttention", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerDecoder", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerDecoderLayer", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerEncoder", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerEncoderLayer", "reference/generated/classes/fairseq2.nn.transformer.StoreAttentionWeights", "reference/generated/classes/fairseq2.optim.lr_scheduler.CosineAnnealingLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.LRSchedulerBase", "reference/generated/classes/fairseq2.optim.lr_scheduler.MyleLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.NoamLR", "reference/generated/classes/fairseq2.optim.lr_scheduler.PolynomialDecayLR", "reference/generated/data/fairseq2.data.ByteStreamError", "reference/generated/data/fairseq2.data.CString", "reference/generated/data/fairseq2.data.CollateOptionsOverride", "reference/generated/data/fairseq2.data.Collater", "reference/generated/data/fairseq2.data.DataPipeline", "reference/generated/data/fairseq2.data.DataPipelineBuilder", "reference/generated/data/fairseq2.data.DataPipelineError", "reference/generated/data/fairseq2.data.FileMapper", "reference/generated/data/fairseq2.data.PathLike", "reference/generated/data/fairseq2.data.RecordError", "reference/generated/data/fairseq2.data.StringLike", "reference/generated/data/fairseq2.data.VocabularyInfo", "reference/generated/data/fairseq2.data.get_last_failed_example", "reference/generated/data/fairseq2.data.is_string_like", "reference/generated/data/fairseq2.data.list_files", "reference/generated/data/fairseq2.data.read_sequence", "reference/generated/data/fairseq2.data.read_zipped_records", "reference/generated/data/fairseq2.data.text.read_text", "reference/generated/data_text/fairseq2.data.text.LineEnding", "reference/generated/data_text/fairseq2.data.text.MultilingualTextTokenizer", "reference/generated/data_text/fairseq2.data.text.SentencePieceDecoder", "reference/generated/data_text/fairseq2.data.text.SentencePieceEncoder", "reference/generated/data_text/fairseq2.data.text.SentencePieceModel", "reference/generated/data_text/fairseq2.data.text.StrSplitter", "reference/generated/data_text/fairseq2.data.text.StrToIntConverter", "reference/generated/data_text/fairseq2.data.text.StrToTensorConverter", "reference/generated/data_text/fairseq2.data.text.TextTokenDecoder", "reference/generated/data_text/fairseq2.data.text.TextTokenEncoder", "reference/generated/data_text/fairseq2.data.text.TextTokenizer", "reference/generated/data_text/fairseq2.data.text.vocabulary_from_sentencepiece", "reference/generated/enums/fairseq2.nn.transformer.TransformerNormOrder", "reference/generated/functions/fairseq2.nn.utils.mask.to_float_mask", "reference/generated/functions/fairseq2.nn.utils.mask.to_padding_mask"], "filenames": ["bibliography.rst", "index.rst", "reference/abc.rst", "reference/all.rst", "reference/classes.rst", "reference/data.rst", "reference/enums.rst", "reference/functions.rst", "reference/generated/abc/fairseq2.gang.Gang.rst", "reference/generated/abc/fairseq2.nn.PositionEncoder.rst", "reference/generated/abc/fairseq2.nn.Projection.rst", "reference/generated/abc/fairseq2.nn.transformer.AttentionMaskGenerator.rst", "reference/generated/abc/fairseq2.nn.transformer.AttentionWeightHook.rst", "reference/generated/abc/fairseq2.nn.transformer.FeedForwardNetwork.rst", "reference/generated/abc/fairseq2.nn.transformer.MultiheadAttention.rst", "reference/generated/abc/fairseq2.nn.transformer.SDPA.rst", "reference/generated/abc/fairseq2.nn.transformer.TransformerDecoder.rst", "reference/generated/abc/fairseq2.nn.transformer.TransformerDecoderLayer.rst", "reference/generated/abc/fairseq2.nn.transformer.TransformerEncoder.rst", "reference/generated/abc/fairseq2.nn.transformer.TransformerEncoderLayer.rst", "reference/generated/classes/fairseq2.nn.Embedding.rst", "reference/generated/classes/fairseq2.nn.IncrementalState.rst", "reference/generated/classes/fairseq2.nn.IncrementalStateBag.rst", "reference/generated/classes/fairseq2.nn.LearnedPositionEncoder.rst", "reference/generated/classes/fairseq2.nn.Linear.rst", "reference/generated/classes/fairseq2.nn.ModuleList.rst", "reference/generated/classes/fairseq2.nn.RotaryEncoder.rst", "reference/generated/classes/fairseq2.nn.SinusoidalPositionEncoder.rst", "reference/generated/classes/fairseq2.nn.TiedProjection.rst", "reference/generated/classes/fairseq2.nn.transformer.ALiBiAttentionMaskGenerator.rst", "reference/generated/classes/fairseq2.nn.transformer.CausalAttentionMaskGenerator.rst", "reference/generated/classes/fairseq2.nn.transformer.RelativePositionSDPA.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardFeedForwardNetwork.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardMultiheadAttention.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerDecoder.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerDecoderLayer.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerEncoder.rst", "reference/generated/classes/fairseq2.nn.transformer.StandardTransformerEncoderLayer.rst", "reference/generated/classes/fairseq2.nn.transformer.StoreAttentionWeights.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.CosineAnnealingLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.LRSchedulerBase.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.MyleLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.NoamLR.rst", "reference/generated/classes/fairseq2.optim.lr_scheduler.PolynomialDecayLR.rst", "reference/generated/data/fairseq2.data.ByteStreamError.rst", "reference/generated/data/fairseq2.data.CString.rst", "reference/generated/data/fairseq2.data.CollateOptionsOverride.rst", "reference/generated/data/fairseq2.data.Collater.rst", "reference/generated/data/fairseq2.data.DataPipeline.rst", "reference/generated/data/fairseq2.data.DataPipelineBuilder.rst", "reference/generated/data/fairseq2.data.DataPipelineError.rst", "reference/generated/data/fairseq2.data.FileMapper.rst", "reference/generated/data/fairseq2.data.PathLike.rst", "reference/generated/data/fairseq2.data.RecordError.rst", "reference/generated/data/fairseq2.data.StringLike.rst", "reference/generated/data/fairseq2.data.VocabularyInfo.rst", "reference/generated/data/fairseq2.data.get_last_failed_example.rst", "reference/generated/data/fairseq2.data.is_string_like.rst", "reference/generated/data/fairseq2.data.list_files.rst", "reference/generated/data/fairseq2.data.read_sequence.rst", "reference/generated/data/fairseq2.data.read_zipped_records.rst", "reference/generated/data/fairseq2.data.text.read_text.rst", "reference/generated/data_text/fairseq2.data.text.LineEnding.rst", "reference/generated/data_text/fairseq2.data.text.MultilingualTextTokenizer.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceDecoder.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceEncoder.rst", "reference/generated/data_text/fairseq2.data.text.SentencePieceModel.rst", "reference/generated/data_text/fairseq2.data.text.StrSplitter.rst", "reference/generated/data_text/fairseq2.data.text.StrToIntConverter.rst", "reference/generated/data_text/fairseq2.data.text.StrToTensorConverter.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenDecoder.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenEncoder.rst", "reference/generated/data_text/fairseq2.data.text.TextTokenizer.rst", "reference/generated/data_text/fairseq2.data.text.vocabulary_from_sentencepiece.rst", "reference/generated/enums/fairseq2.nn.transformer.TransformerNormOrder.rst", "reference/generated/functions/fairseq2.nn.utils.mask.to_float_mask.rst", "reference/generated/functions/fairseq2.nn.utils.mask.to_padding_mask.rst"], "titles": ["Bibliography", "fairseq2 documentation", "ABCs and Protocols", "All", "Classes", "fairseq2.data", "Enums", "Functions", "Gang", "PositionEncoder", "Projection", "AttentionMaskGenerator", "AttentionWeightHook", "FeedForwardNetwork", "MultiheadAttention", "SDPA", "TransformerDecoder", "TransformerDecoderLayer", "TransformerEncoder", "TransformerEncoderLayer", "Embedding", "IncrementalState", "IncrementalStateBag", "LearnedPositionEncoder", "Linear", "ModuleList", "RotaryEncoder", "SinusoidalPositionEncoder", "TiedProjection", "ALiBiAttentionMaskGenerator", "CausalAttentionMaskGenerator", "RelativePositionSDPA", "StandardFeedForwardNetwork", "StandardMultiheadAttention", "StandardTransformerDecoder", "StandardTransformerDecoderLayer", "StandardTransformerEncoder", "StandardTransformerEncoderLayer", "StoreAttentionWeights", "CosineAnnealingLR", "LRSchedulerBase", "MyleLR", "NoamLR", "PolynomialDecayLR", "fairseq2.data.ByteStreamError", "CString", "CollateOptionsOverride", "Collater", "DataPipeline", "DataPipelineBuilder", "fairseq2.data.DataPipelineError", "FileMapper", "PathLike", "fairseq2.data.RecordError", "StringLike", "VocabularyInfo", "get_last_failed_example", "is_string_like", "list_files", "read_sequence", "read_zipped_records", "read_text", "LineEnding", "MultilingualTextTokenizer", "SentencePieceDecoder", "SentencePieceEncoder", "SentencePieceModel", "StrSplitter", "StrToIntConverter", "StrToTensorConverter", "TextTokenDecoder", "TextTokenEncoder", "TextTokenizer", "vocabulary_from_sentencepiece", "TransformerNormOrder", "to_float_mask", "to_padding_mask"], "terms": {"altdj": [0, 33], "23": [0, 33], "joshua": 0, "ainsli": [0, 33], "jame": 0, "lee": 0, "thorp": 0, "michiel": 0, "de": [0, 72], "jong": 0, "yuri": 0, "zemlyanskii": 0, "federico": 0, "lebr\u00f3n": 0, "sumit": 0, "sanghai": 0, "gqa": 0, "train": [0, 1, 20, 25, 39, 41, 42, 43], "gener": [0, 1, 11, 29, 30, 34, 63, 72], "multi": [0, 14, 33, 72], "queri": [0, 14, 15, 31, 33], "transform": [0, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 74], "model": [0, 1, 11, 13, 14, 16, 17, 18, 19, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42, 63, 64, 65, 73], "from": [0, 5, 8, 23, 24, 25, 27, 30, 39, 40, 41, 42, 43, 47, 48, 49, 50, 63, 64, 70], "head": [0, 14, 29, 31, 33], "checkpoint": 0, "2023": 0, "arxiv": 0, "2305": 0, "13245": 0, "dyi": [0, 31], "19": [0, 31], "zihang": 0, "dai": [0, 31], "zhilin": 0, "yang": 0, "yime": 0, "jaim": 0, "carbonel": 0, "quoc": 0, "v": [0, 12, 14, 15, 31, 33], "le": 0, "ruslan": 0, "salakhutdinov": 0, "xl": 0, "attent": [0, 11, 12, 14, 15, 16, 17, 29, 30, 31, 33, 34, 35, 37, 38], "languag": [0, 1, 63, 72], "beyond": 0, "fix": [0, 20, 27, 49], "length": [0, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 47, 76], "context": 0, "2019": 0, "1901": 0, "02860": 0, "fgj19": [0, 34, 36], "angela": 0, "fan": [0, 34, 36], "edouard": 0, "grave": 0, "armand": 0, "joulin": 0, "reduc": [0, 8], "depth": 0, "demand": 0, "structur": 0, "dropout": [0, 15, 31, 32, 35, 37], "url": 0, "http": 0, "org": 0, "ab": 0, "1909": 0, "11556": 0, "doi": 0, "10": [0, 5, 30, 49, 68], "48550": 0, "lh17": [0, 39], "ilya": 0, "loshchilov": [0, 39], "frank": 0, "hutter": [0, 39], "sgdr": 0, "stochast": 0, "gradient": [0, 20], "descent": 0, "warm": 0, "restart": [0, 39], "2017": 0, "1608": 0, "03983": 0, "psl21": [0, 29], "ofir": 0, "press": [0, 29], "noah": 0, "A": [0, 14, 21, 33, 47, 48, 51, 63], "smith": 0, "mike": 0, "lewi": 0, "short": 0, "test": 0, "long": [0, 21, 47], "linear": [0, 10, 28], "bias": 0, "enabl": [0, 49, 51], "input": [0, 5, 8, 9, 10, 15, 20, 21, 23, 24, 26, 27, 28, 31, 47, 67], "extrapol": 0, "2021": 0, "2108": 0, "12409": 0, "swo21": [0, 33, 35, 37, 74], "sam": 0, "shleifer": [0, 33, 35, 37, 74], "jason": 0, "weston": 0, "myle": [0, 41], "ott": [0, 41], "normform": 0, "improv": 0, "pretrain": 0, "extra": [0, 25], "normal": [0, 32, 34, 35, 36, 37, 74], "2110": 0, "09456": 0, "slp": [0, 26], "21": [0, 26], "jianlin": 0, "su": [0, 26], "yu": 0, "lu": 0, "shengfeng": 0, "pan": 0, "ahm": 0, "murtadha": 0, "bo": 0, "wen": 0, "yunfeng": 0, "liu": 0, "roform": 0, "enhanc": 0, "rotari": 0, "posit": [0, 9, 14, 22, 23, 26, 27, 31, 33, 48], "embed": [0, 23], "2104": 0, "09864": 0, "vsp": [0, 27, 32, 33, 34, 35, 36, 37, 42, 74], "17": [0, 27, 32, 33, 34, 35, 36, 37, 42, 74], "ashish": 0, "vaswani": [0, 27, 32, 33, 34, 35, 36, 37, 42, 74], "noam": [0, 41, 42], "shazeer": [0, 42], "niki": 0, "parmar": 0, "jakob": 0, "uszkoreit": 0, "llion": 0, "jone": 0, "aidan": 0, "n": [0, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 29, 30, 31, 32, 33, 34, 35, 36, 37, 76], "gomez": 0, "lukasz": 0, "kaiser": 0, "illia": 0, "polosukhin": 0, "i": [0, 1, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 47, 48, 49, 51, 53, 55, 57, 63, 65, 71, 76], "all": [0, 1, 8, 10, 22, 24, 25, 28, 39, 41, 43, 46, 47, 48, 49, 51, 58, 67], "you": [0, 5, 51], "need": [0, 21, 47], "1706": 0, "03762": 0, "xyh": [0, 74], "20": [0, 74], "ruibin": 0, "xiong": [0, 74], "yunchang": 0, "di": 0, "he": 0, "kai": 0, "zheng": 0, "shuxin": 0, "chen": 0, "xing": 0, "huishuai": 0, "zhang": 0, "yanyan": 0, "lan": 0, "liwei": 0, "wang": 0, "tie": 0, "yan": 0, "On": 0, "layer": [0, 14, 16, 17, 18, 19, 25, 32, 34, 35, 36, 37, 74], "architectur": 0, "2020": 0, "2002": 0, "04745": 0, "sequenc": [1, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 47, 48, 49, 55, 59, 67, 76], "toolkit": 1, "allow": [1, 47, 48], "research": 1, "develop": 1, "custom": 1, "translat": [1, 72], "summar": 1, "other": [1, 5], "content": [1, 51], "task": [1, 63, 72], "data": [1, 10, 24, 28, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73], "bibliographi": 1, "provid": [5, 38], "python": [5, 25, 45, 48, 51], "build": 5, "c": 5, "datapipelin": [5, 49], "The": [5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 51, 55, 58, 59, 63, 64, 65, 67, 70, 71, 72, 75, 76], "dataload": [5, 67], "abl": 5, "leverag": 5, "sever": [5, 48, 49, 51], "thread": 5, "work": [5, 8], "around": [5, 48], "global": 5, "interpret": 5, "lock": 5, "limit": 5, "also": [5, 39, 48, 51], "better": 5, "perform": 5, "than": [5, 34, 36, 49], "pure": 5, "look": [5, 51], "like": 5, "thi": [5, 8, 21, 22, 24, 25, 27, 29, 30, 38, 39, 41, 42, 43, 45, 46, 48, 49, 51], "read_text": [5, 67], "file": [5, 44, 51, 58, 60, 61, 63, 67], "tsv": [5, 67], "map": [5, 48, 49, 51, 67], "lambda": [5, 49, 67], "x": [5, 10, 20, 24, 25, 28, 49, 67], "str": [5, 45, 46, 48, 49, 51, 52, 54, 57, 58, 63, 64, 65, 67, 70, 71, 72], "split": [5, 45, 67], "t": [5, 22, 39, 41, 42, 43, 44, 67], "1": [5, 22, 23, 24, 25, 27, 33, 35, 37, 39, 40, 41, 42, 43, 46, 47, 49, 62, 65, 67, 74], "lower": 5, "filter": [5, 49], "len": 5, "function": [5, 38, 49, 67, 68, 69], "item": 5, "go": [5, 67], "through": 5, "pipelin": [5, 48, 49, 50, 61], "don": 5, "have": [5, 47, 48], "flat": 5, "tensor": [5, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 47, 63, 64, 65, 69, 70, 71, 72, 75, 76], "can": [5, 14, 33, 44, 48, 49, 51], "tupl": [5, 15, 16, 17, 18, 19, 31, 34, 35, 36, 37, 38, 47], "dictionari": [5, 20, 47, 48, 67], "oper": [5, 8, 48], "specifi": [5, 20, 33, 46, 49, 51, 63, 74], "specif": [5, 11, 47, 72, 76], "notabl": 5, "datapipelinebuild": [5, 48, 58, 59, 60, 61], "ha": [5, 12, 21, 39, 49], "selector": [5, 46, 49], "argument": [5, 72], "choos": 5, "appli": [5, 10, 24, 28, 32, 33, 34, 36, 46, 49, 74], "If": [5, 15, 16, 18, 20, 22, 24, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 47, 48, 49, 58, 63, 72], "3": [5, 23, 25, 27, 30, 42, 47, 49], "select": [5, 21, 49], "third": 5, "foo": 5, "valu": [5, 12, 14, 15, 22, 31, 33, 39, 47, 62, 74], "correspond": [5, 20, 21, 41, 42, 43, 67], "kei": [5, 12, 14, 15, 31, 33, 47, 48, 51], "nest": 5, "separ": [5, 49], "follow": [5, 29, 30, 38, 47, 51, 58], "For": [5, 47, 51], "y": 5, "2": [5, 23, 27, 39, 47, 49, 67, 74], "4": [5, 23, 27, 30, 47], "z": 5, "5": [5, 25, 27, 42, 47, 49], "bar": 5, "6": [5, 27], "refer": [5, 39, 42, 72], "accept": 5, "them": [5, 8, 35, 37, 49], "comma": 5, "list": [5, 25, 45, 47, 49, 58, 63, 64, 67, 70], "exampl": [5, 47, 48, 49, 67], "multipli": 5, "leav": 5, "unmodifi": 5, "helper": 5, "method": [5, 22, 24], "tool": 5, "token": [5, 55, 63, 64, 65, 70, 71, 72], "convert": [5, 67, 75, 76], "byte": [5, 45, 51], "class": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 55, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74], "fairseq2": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "rank": 8, "size": [8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 29, 30, 31, 32, 33, 34, 35, 36, 37, 49, 55, 69, 76], "devic": [8, 23, 24, 26, 27, 31, 32, 33, 34, 35, 36, 37, 63, 65, 72], "sourc": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "base": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 55, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74], "abc": [8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 40, 70, 71, 72], "repres": [8, 12, 13, 14, 16, 17, 18, 19, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 55, 63, 72, 76], "set": [8, 22, 25, 33, 63], "process": [8, 17, 19, 35, 37, 49], "collect": 8, "paramet": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 51, 58, 59, 63, 64, 65, 67, 70, 71, 72, 75, 76], "int": [8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 31, 32, 33, 39, 41, 42, 43, 47, 49, 51, 55, 67, 68], "number": [8, 9, 14, 15, 22, 23, 25, 26, 27, 29, 31, 33, 39, 41, 42, 43, 49, 65, 71, 76], "ar": [8, 10, 24, 27, 28, 33, 72], "part": [8, 30, 49], "associ": [8, 39, 41, 42, 43, 72], "abstract": [8, 9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 40, 70, 71, 72], "all_gath": 8, "output_tensor": 8, "input_tensor": 8, "gather": 8, "put": 8, "singl": [8, 47, 49], "output": [8, 10, 16, 17, 18, 19, 21, 24, 28, 32, 33, 34, 35, 36, 37], "accomod": 8, "element": [8, 55, 59, 76], "current": [8, 39, 40, 41, 42, 43, 48, 49], "all_reduc": 8, "op": 8, "across": 8, "reduceoper": 8, "wise": 8, "as_process_group": 8, "return": [8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 47, 48, 49, 51, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "group": [8, 33, 39, 40, 41, 42, 43], "type": [8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 45, 47, 48, 49, 51, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76], "processgroup": 8, "barrier": 8, "synchron": 8, "nn": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 74, 75, 76], "encoding_dim": [9, 23, 26, 27], "max_seq_len": [9, 23, 26, 27], "modul": [9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 62, 74], "encod": [9, 16, 17, 18, 19, 23, 26, 27, 31, 33, 34, 35, 36, 37, 61, 63, 65, 71, 72], "inform": [9, 22, 23, 26, 27, 35, 37, 72, 73], "dimension": [9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 42], "none": [9, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 55, 58, 61, 62, 63, 65, 66, 67, 69, 71, 72, 74, 75, 76], "expect": [9, 22, 23, 26, 27], "maximum": [9, 22, 23, 26, 27], "_do_forward": [9, 26], "seq": [9, 11, 13, 16, 17, 18, 19, 23, 26, 27, 29, 30, 32, 34, 35, 36, 37, 47, 59, 76], "padding_mask": [9, 14, 16, 17, 18, 19, 23, 26, 27, 33, 34, 35, 36, 37], "state_bag": [9, 14, 16, 17, 23, 26, 27, 33, 34, 35], "shape": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 47, 49, 65, 71, 75, 76], "": [9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 45, 48, 49, 57, 65, 67, 68, 69, 71, 74, 76], "e": [9, 20, 23, 26, 27, 33, 39], "where": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 65, 71, 76], "ani": [9, 15, 20, 21, 23, 25, 26, 27, 31, 47, 48, 49, 51, 56, 59, 75, 76], "batch": [9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 46, 47, 49, 76], "dimens": [9, 10, 15, 23, 24, 26, 27, 28, 31, 47, 76], "includ": [9, 15, 23, 26, 27, 31, 43, 76], "float": [9, 14, 15, 16, 17, 18, 19, 23, 25, 26, 27, 31, 32, 33, 34, 35, 36, 37, 39, 41, 43, 48, 75, 76], "pad": [9, 14, 16, 17, 18, 19, 23, 26, 27, 33, 34, 35, 36, 37, 46, 47, 55, 76], "mask": [9, 11, 14, 15, 16, 17, 18, 19, 23, 26, 27, 29, 30, 31, 33, 34, 35, 36, 37, 75, 76], "incrementalstatebag": [9, 14, 16, 17, 23, 26, 27, 33, 34, 35], "state": [9, 14, 16, 17, 21, 22, 23, 26, 27, 33, 34, 35, 39, 40, 41, 42, 43, 48, 49], "bag": [9, 14, 16, 17, 22, 23, 26, 27, 33, 34, 35], "us": [9, 14, 16, 17, 21, 22, 23, 24, 26, 27, 28, 32, 33, 34, 35, 36, 37, 42, 43, 45, 46, 47, 48, 49, 51, 55, 63, 72], "increment": [9, 14, 16, 17, 21, 22, 23, 26, 27, 33, 34, 35], "decod": [9, 14, 16, 17, 21, 22, 23, 26, 27, 33, 34, 35, 63, 64, 70, 72], "same": [9, 10, 13, 15, 16, 17, 18, 19, 23, 24, 26, 27, 28, 31, 32, 34, 35, 36, 37, 46, 47, 48, 49, 51, 76], "forward": [9, 10, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37], "input_dim": [10, 24], "output_dim": [10, 24], "incom": [10, 24, 28], "h_": [10, 24, 28], "inp": [10, 24, 28], "out": [10, 24, 28], "last": [10, 24, 28, 39, 40, 41, 42, 43, 47, 49, 51], "arg": [11, 12, 25, 39, 40, 41, 42, 43], "kwarg": [11, 12], "protocol": [11, 12, 29, 30, 38], "an": [11, 14, 21, 24, 25, 29, 30, 32, 33, 34, 39, 40, 41, 42, 43, 45, 48, 50, 51, 55, 76], "__call__": [11, 12, 29, 30, 38, 47, 51, 64, 65, 67, 68, 69, 70, 71], "which": [11, 14, 22, 27, 29, 30, 33, 38, 39, 40, 41, 42, 43, 63, 72], "m": [11, 12, 13, 14, 16, 17, 18, 19, 22, 23, 27, 29, 30, 32, 33, 34, 35, 36, 37, 38], "implement": [11, 33, 39, 41, 72], "defin": [11, 63], "hook": [12, 14, 33], "pass": [12, 48], "register_attn_weight_hook": [12, 14, 33], "attn": [12, 14, 33, 38], "attn_weight": [12, 14, 33, 38], "multiheadattent": [12, 33, 35, 37], "comput": [12, 14, 15, 17, 31, 33, 35, 39, 40, 41, 42, 43], "weight": [12, 14, 15, 17, 24, 28, 31, 33, 35, 38, 48], "s_": [12, 14, 15, 16, 17, 31, 33, 34, 35], "kv": [12, 14, 15, 31, 33], "model_dim": [13, 14, 16, 17, 18, 19, 31, 32, 33], "feed": [13, 32, 35, 37], "network": [13, 32, 35, 37], "project": [13, 24, 28, 32, 33], "num_head": [14, 29, 31, 33], "_run_attn_weight_hook": [14, 33], "run": [14, 33], "regist": [14, 33], "attn_mask": [14, 33], "key_padding_mask": [14, 33], "k": [14, 15, 24, 31, 33], "ad": [14, 15, 17, 31, 33, 35, 37], "befor": [14, 15, 17, 25, 31, 33, 35, 37, 39], "indic": [14, 20, 33, 64, 65, 67, 70, 71, 72], "ignor": [14, 33], "purpos": [14, 33], "call": [14, 16, 18, 21, 22, 33, 34, 36, 38, 39, 40, 41, 42, 43, 48, 67, 68, 69], "everi": [14, 22, 25, 33, 39, 40, 41, 42, 43, 49, 59], "time": [14, 21, 33, 48, 49], "after": [14, 22, 33, 39, 42, 43, 74], "attentionweighthook": [14, 33, 38], "handl": [14, 33], "remov": [14, 33], "removablehandl": [14, 33], "attn_dropout_p": [15, 31], "0": [15, 23, 25, 27, 30, 31, 32, 34, 35, 36, 37, 39, 41, 43, 47, 49, 65, 67, 74], "scale": [15, 31, 33, 35, 37, 39, 41], "dot": [15, 31, 33], "product": [15, 31, 33], "probabl": [15, 25, 31, 32, 35, 37], "needs_weight": [15, 31], "fals": [15, 24, 31, 33, 35, 37, 39, 40, 41, 42, 43, 47, 48, 49, 61, 63, 64, 65, 67, 72], "bool": [15, 24, 31, 32, 33, 35, 37, 39, 41, 42, 43, 48, 49, 63, 72], "true": [15, 24, 31, 32, 33, 35, 37, 39, 41, 42, 43, 47, 48, 49, 57, 63, 72], "encoder_output": [16, 17, 34, 35], "encoder_padding_mask": [16, 17, 34, 35], "layer_output_hook": [16, 18, 34, 36], "enc": [16, 17, 34, 35], "m_": [16, 17, 34, 35], "encoder_out": [16, 34], "decoderlayeroutputhook": [16, 34], "each": [16, 18, 34, 36, 39, 41, 42, 43, 47, 48, 49, 60, 74, 76], "stack": [16, 18, 34, 36], "self_attn_mask": [17, 35], "self": [17, 29, 30, 35, 37, 38, 39, 40, 41, 42, 43, 49, 67, 68, 69], "encoderlayeroutputhook": [18, 36], "num_embed": 20, "embedding_dim": 20, "pad_idx": [20, 46, 47, 55], "store": [20, 22, 38], "tabl": [20, 31], "entri": [20, 39, 40, 41, 42, 43, 67], "do": 20, "contribut": 20, "therefor": 20, "updat": [20, 39, 41, 42, 43], "dure": [20, 21, 22, 25, 33, 39, 43], "hold": [21, 22, 25], "special": 21, "mode": [21, 63, 72], "infer": [21, 61], "onli": [21, 49, 67], "receiv": 21, "previou": 21, "must": [21, 63], "produc": [21, 33], "next": 21, "thu": 21, "cach": [21, 51], "term": 21, "about": [21, 39], "reorder": [21, 22], "new_ord": [21, 22], "rearrang": 21, "accord": 21, "new": [21, 49], "order": [21, 32, 34, 35, 36, 37, 62, 74], "when": [21, 44, 47, 48, 50, 53], "chang": 21, "typic": [21, 72], "case": [21, 49], "beam": 21, "search": 21, "between": [21, 45, 72], "step": [21, 22, 33, 39, 41, 42, 43], "It": [21, 22, 39, 40, 41, 42, 43, 48, 63], "frequent": 21, "torch": [21, 23, 24, 25, 27, 30], "index_select": 21, "max_num_step": 22, "object": [22, 29, 30, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 51, 55, 66, 67, 68, 69], "take": [22, 49], "get_stat": 22, "kl": 22, "get": [22, 51, 65, 71], "present": 22, "doe": 22, "match": [22, 48, 49, 58, 63], "increment_step": 22, "delta": 22, "should": [22, 39, 40, 41, 42, 43, 46], "keep": [22, 49, 67], "track": 22, "see": [22, 27, 35, 37, 46, 49], "incrementalst": 22, "more": [22, 27, 35, 37, 39, 49, 72], "set_stat": 22, "final": [23, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 39, 41, 42, 43, 63, 64, 65, 66], "dtype": [23, 24, 31, 32, 33, 34, 35, 36, 37, 69, 75], "positionencod": [23, 26, 27, 33], "learn": [23, 24, 32, 33, 39, 40, 41, 42, 43], "usag": [23, 25, 27, 30, 49, 67], "import": [23, 25, 27, 30], "position_encod": [23, 27], "16": [23, 27], "ones": [23, 27], "1135": 23, "5548": 23, "4293": 23, "0112": 23, "po": [23, 27], "2364": 23, "6009": 23, "3865": 23, "4810": 23, "4746": 23, "4544": 23, "2761": 23, "8828": 23, "grad_fn": 23, "squeezebackward1": 23, "reset_paramet": [23, 24, 26, 27, 31, 33, 35, 37], "reset": [23, 24, 26, 27, 31, 33, 35, 37, 48], "buffer": [23, 24, 26, 27, 31, 33, 35, 37, 49], "bia": [24, 28, 32, 33], "skip_init": 24, "unless": 24, "overridden": 24, "subclass": [24, 72], "initi": [24, 27, 39, 41, 43], "mathcal": 24, "u": [24, 72], "sqrt": [24, 41, 42], "frac": [24, 27, 39, 41, 42, 43], "text": [24, 27, 39, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73], "ident": 24, "addit": [24, 32, 33, 39], "left": 24, "uniniti": 24, "becom": 24, "noop": 24, "intend": 24, "author": [24, 42], "who": [24, 49], "want": 24, "differ": [24, 27, 47, 72], "drop_p": 25, "submodul": 25, "extend": [25, 33], "featur": 25, "option": 25, "drop": [25, 49], "random": 25, "iter": [25, 48], "layer1": 25, "layer2": 25, "layer3": 25, "drop_it": 25, "might": 25, "over": [25, 43, 48], "add": 25, "append": 25, "given": [25, 51, 67, 68], "end": [25, 39, 45, 48, 55], "insert": 25, "index": [25, 39, 41, 42, 43, 49, 55, 76], "rel": [26, 31, 39, 51], "describ": [26, 29, 31, 32, 33, 34, 35, 36, 37, 39, 42, 47, 55, 74], "et": [26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 42, 74], "al": [26, 27, 29, 31, 32, 33, 34, 35, 36, 37, 42, 74], "reset_non_persistent_buff": [26, 27], "non": [26, 27, 58], "persist": [26, 27, 48], "_legacy_pad_idx": 27, "sinusoid": 27, "tensor2tensor": 27, "slightli": 27, "descript": 27, "section": [27, 42], "mean": 27, "instead": 27, "pe_": 27, "2i": 27, "sin": 27, "10000": 27, "d_": 27, "co": [27, 39], "we": 27, "geq": 27, "here": 27, "0000e": 27, "00": 27, "9": 27, "4147e": 27, "01": 27, "04": 27, "4030e": 27, "0930e": 27, "02": 27, "1615e": 27, "anoth": 28, "instanc": [28, 33, 34, 49], "share": 28, "attentionmaskgener": [29, 30, 34], "alibi": 29, "h": 29, "causal": 30, "whose": 30, "upper": 30, "triangular": 30, "abov": 30, "main": 30, "diagon": 30, "fill": 30, "neg": 30, "infin": 30, "while": [30, 48, 49, 50, 53, 63, 72], "its": [30, 48], "rest": 30, "zero": [30, 33, 34, 36, 45], "g": [30, 33], "empti": [30, 33, 58], "inf": 30, "pos_encod": [31, 33], "sdpa": [31, 33], "param": 31, "inner_dim": 32, "inner_activ": 32, "inner_dropout_p": 32, "norm_ord": [32, 34, 35, 36, 37], "transformernormord": [32, 34, 35, 36, 37], "post": [32, 34, 35, 36, 37, 74], "layer_norm_fn": [32, 34, 35, 36, 37], "feedforwardnetwork": [32, 35, 37], "inner": 32, "both": 32, "activ": 32, "relu": 32, "layernormfactori": [32, 34, 35, 36, 37], "factori": [32, 33, 34, 35, 36, 37], "construct": [32, 33, 34, 35, 36, 37, 63, 72], "static_kv": 33, "num_key_value_head": 33, "q_proj": 33, "k_proj": 33, "v_proj": 33, "add_bias_kv": 33, "add_zero_attn": 33, "scale_head": 33, "output_proj": 33, "state_factori": 33, "assum": 33, "static": [33, 48], "equival": 33, "standard": 33, "mha": 33, "mqa": 33, "default": [33, 63, 67], "explicitli": 33, "attentionstatefactori": 33, "attentionst": 33, "self_attn_mask_gen": 34, "layer_drop_p": [34, 36], "transformerdecod": 34, "modulelist": [34, 36], "causalattentionmaskgener": 34, "greater": [34, 36], "layerdrop": [34, 36], "self_attn": [35, 37], "encoder_decoder_attn": 35, "ffn": [35, 37], "scale_residu": [35, 37], "dropout_p": [35, 37], "transformerdecoderlay": 35, "residu": [35, 37, 74], "transformerencod": 36, "transformerencoderlay": 37, "storag": 38, "mutablesequ": 38, "optim": [39, 40, 41, 42, 43], "lr_schedul": [39, 40, 41, 42, 43], "cycle_len": 39, "num_warmup_step": [39, 41, 42, 43], "cycle_mul": 39, "lr_mul": 39, "start_lr": [39, 41, 43], "final_lr": [39, 43], "last_epoch": [39, 40, 41, 42, 43], "verbos": [39, 40, 41, 42, 43], "lrschedulerbas": [39, 41, 42, 43], "rate": [39, 40, 41, 42, 43], "schedul": [39, 40, 41, 42, 43], "warmup": [39, 41, 42, 43], "eta_t": [39, 41, 42, 43], "eta_": [39, 41, 42, 43], "t_": [39, 41, 42, 43], "pi": 39, "anneal": 39, "cycl": 39, "t_i": 39, "taken": 39, "sinc": 39, "total": [39, 43], "within": 39, "th": 39, "cosin": 39, "effect": 39, "start": [39, 62, 74], "larg": [39, 49], "rapidli": 39, "decreas": [39, 41, 42, 43], "minimum": 39, "being": [39, 48, 49], "increas": [39, 41, 42, 43, 49], "again": 39, "pleas": 39, "paper": [39, 42], "detail": [39, 46, 49], "In": [39, 42], "origin": [39, 41, 47], "support": [39, 45, 63], "phase": 39, "linearli": [39, 41, 42, 43], "first": [39, 41, 42, 43, 48, 67], "chainabl": [39, 41, 42, 43], "factor": 39, "grow": 39, "respect": [39, 41, 43], "epoch": [39, 40, 41, 42, 43], "print": [39, 41, 42, 43], "messag": [39, 41, 42, 43], "stdout": [39, 41, 42, 43], "get_last_lr": [39, 40, 41, 42, 43], "load_state_dict": [39, 40, 41, 42, 43, 48], "state_dict": [39, 40, 41, 42, 43, 48, 49], "load": [39, 40, 41, 42, 43, 49], "dict": [39, 40, 41, 42, 43, 47, 48, 51, 67], "print_lr": [39, 40, 41, 42, 43], "is_verbos": [39, 40, 41, 42, 43], "lr": [39, 40, 41, 42, 43], "displai": [39, 40, 41, 42, 43], "contain": [39, 40, 41, 42, 43, 48], "variabl": [39, 40, 41, 42, 43], "__dict__": [39, 40, 41, 42, 43], "_lrschedul": 40, "version": [41, 49], "noamlr": 41, "preserv": [41, 47], "min": [41, 42], "essenti": 41, "squar": [41, 42], "root": [41, 42, 51], "wa": [41, 47], "propos": 41, "fairseq": 41, "under": [41, 58], "name": [41, 48, 51, 62, 67, 74], "inversesquarerootlr": 41, "thereaft": [41, 42, 43], "proportion": [41, 42], "invers": [41, 42], "commonli": 42, "second": [42, 48, 67], "num_step": 43, "power": 43, "polynomi": 43, "decai": 43, "p": 43, "degre": 43, "expon": 43, "except": [44, 50, 53], "rais": [44, 48, 50, 53], "dataset": [44, 53], "read": [44, 48, 49, 50, 51, 53, 59, 60, 61, 67], "immut": 45, "utf": 45, "8": [45, 49], "string": [45, 67], "copi": 45, "marshal": 45, "nativ": [45, 48], "code": 45, "lstrip": 45, "whitespac": 45, "begin": [45, 55, 74], "rstrip": 45, "sep": [45, 67], "word": 45, "delimit": 45, "pad_to_multipl": [46, 47], "overrid": [46, 47], "how": 46, "collat": 46, "creat": [46, 47, 49, 63, 67, 72], "particular": 46, "column": [46, 47, 49, 67], "idx": 46, "multipl": [46, 47], "syntax": [46, 49, 58], "concaten": 47, "otherwis": 47, "requir": 47, "made": 47, "enough": 47, "fit": 47, "longest": 47, "round": [47, 48], "up": [47, 51], "is_rag": 47, "seq_len": [47, 76], "shortest": 47, "alwai": 47, "collateoptionsoverrid": 47, "disk": 48, "resum": 48, "later": 48, "still": 48, "segfault": 48, "wors": 48, "__iter__": [48, 62, 74], "modifi": 48, "intern": 48, "so": [48, 51], "safe": 48, "strict": [48, 49], "restor": [48, 49], "previous": 48, "enforc": [48, 51], "move": 48, "back": [48, 63], "round_robin": 48, "stop_at_shortest": 48, "extract": 48, "robin": 48, "stop": 48, "reach": 48, "circl": 48, "finish": 48, "until": 48, "sampl": [48, 49], "data_pipelin": 48, "desir": 48, "distribut": 48, "uniform": 48, "zip": [48, 60], "zip_to_shortest": 48, "flatten": 48, "disable_parallel": 48, "togeth": 48, "assign": 48, "sequenti": 48, "properti": [48, 65, 71], "is_broken": 48, "broken": 48, "futur": 48, "datapipelineerror": 48, "api": 49, "and_return": [49, 67], "max_num_warn": 49, "bucket": 49, "bucket_s": 49, "drop_remaind": 49, "combin": 49, "consecut": 49, "fewer": 49, "bucket_by_length": 49, "similar": 49, "predic": 49, "those": 49, "callabl": 49, "fn": 49, "num_parallel_cal": 49, "yield": 49, "12": 49, "15": 49, "result": 49, "core": 49, "b": 49, "11": 49, "13": 49, "thei": 49, "automat": 49, "chain": 49, "f1": 49, "f2": 49, "effici": 49, "colum": 49, "parallel": 49, "prefetch": 49, "num_exampl": 49, "background": 49, "shard": 49, "shard_idx": 49, "num_shard": 49, "shuffl": 49, "shuffle_window": 49, "intermedi": 49, "randomli": 49, "replac": 49, "memori": [49, 51, 63, 72], "full": 49, "save": 49, "ensur": 49, "preemption": 49, "lost": 49, "significantli": 49, "disabl": 49, "skip": 49, "most": 49, "yield_from": 49, "error": 50, "occur": 50, "root_dir": 51, "cached_fd_count": 51, "slice": 51, "big_fil": 51, "txt": 51, "1024": 51, "48": 51, "offset": 51, "cstring": [51, 52, 54, 57, 58, 63, 64, 65, 67, 70, 71], "o": [51, 52, 58, 63], "pathlik": [51, 58, 63], "directori": 51, "warn": 51, "happili": 51, "system": 51, "lru": 51, "especi": 51, "filenam": 51, "pars": [51, 68], "path": [51, 58], "memoryblock": 51, "block": 51, "regular": 51, "filemapperoutput": 51, "alia": [52, 54], "union": [52, 54], "corrupt": 53, "record": 53, "encount": 53, "unk_idx": 55, "bos_idx": 55, "eos_idx": 55, "vocabulari": [55, 72, 73], "symbol": 55, "unknown": 55, "typeguard": 57, "pathnam": [58, 60, 61, 63, 66], "pattern": 58, "recurs": 58, "travers": 58, "fnmatch": 58, "archiv": 60, "line_end": 61, "lineend": 61, "ltrim": 61, "rtrim": 61, "skip_empti": 61, "memory_map": 61, "block_siz": 61, "open": 61, "line": 61, "one": [61, 67], "qualnam": [62, 74], "boundari": [62, 74], "enum": [62, 74], "classmethod": [62, 74], "member": [62, 74], "definit": [62, 74], "source_lang": 63, "target_lang": 63, "default_source_lang": 63, "default_target_lang": 63, "texttoken": 63, "bilingu": 63, "multilingu": [63, 72], "sentencepiec": 63, "user": 63, "valid": [63, 72], "create_encod": [63, 72], "target": [63, 72], "fall": 63, "create_decod": [63, 72], "texttokendecod": [63, 64, 72], "lang": [63, 72], "pin_memori": [63, 65, 72], "either": 63, "depend": 63, "pin": [63, 72], "texttokenencod": [63, 65, 72], "revers": [64, 65], "token_indic": [64, 70], "prefix_token": 65, "suffix_token": 65, "enable_sampl": 65, "nbest_siz": 65, "alpha": 65, "sentenc": [65, 70, 71, 72], "prefix_indic": [65, 71], "prefix": [65, 71], "suffix_indic": [65, 71], "suffix": [65, 71], "control_symbol": 66, "exclud": 67, "charact": 67, "tab": 67, "Will": 67, "per": 67, "va": 67, "cc": 67, "BY": 67, "franc": 67, "tatoeba": 67, "en": [67, 72], "fr": 67, "integ": 68, "vocab_info": 72, "vocabularyinfo": [72, 73], "concret": 72, "job": 72, "distinguish": 72, "transcript": 72, "connect": 74, "pre": 74, "pre_with_normform": 74, "util": [75, 76], "boolean": 75, "point": 75, "arrai": 76}, "objects": {"fairseq2.data": [[44, 0, 1, "", "ByteStreamError"], [45, 1, 1, "", "CString"], [46, 1, 1, "", "CollateOptionsOverride"], [47, 1, 1, "", "Collater"], [48, 1, 1, "", "DataPipeline"], [49, 1, 1, "", "DataPipelineBuilder"], [50, 0, 1, "", "DataPipelineError"], [51, 1, 1, "", "FileMapper"], [52, 4, 1, "", "PathLike"], [53, 0, 1, "", "RecordError"], [54, 4, 1, "", "StringLike"], [55, 1, 1, "", "VocabularyInfo"], [56, 6, 1, "", "get_last_failed_example"], [57, 6, 1, "", "is_string_like"], [58, 6, 1, "", "list_files"], [59, 6, 1, "", "read_sequence"], [60, 6, 1, "", "read_zipped_records"]], "fairseq2.data.CString": [[45, 2, 1, "", "bytes"], [45, 2, 1, "", "lstrip"], [45, 2, 1, "", "rstrip"], [45, 2, 1, "", "split"]], "fairseq2.data.Collater": [[47, 2, 1, "", "__call__"]], "fairseq2.data.DataPipeline": [[48, 2, 1, "", "__iter__"], [48, 3, 1, "", "is_broken"], [48, 2, 1, "", "load_state_dict"], [48, 2, 1, "", "reset"], [48, 2, 1, "", "round_robin"], [48, 2, 1, "", "sample"], [48, 2, 1, "", "state_dict"], [48, 2, 1, "", "zip"]], "fairseq2.data.DataPipelineBuilder": [[49, 2, 1, "", "and_return"], [49, 2, 1, "", "bucket"], [49, 2, 1, "", "bucket_by_length"], [49, 2, 1, "", "filter"], [49, 2, 1, "", "map"], [49, 2, 1, "", "prefetch"], [49, 2, 1, "", "shard"], [49, 2, 1, "", "shuffle"], [49, 2, 1, "", "skip"], [49, 2, 1, "", "take"], [49, 2, 1, "", "yield_from"]], "fairseq2.data.FileMapper": [[51, 2, 1, "", "__call__"]], "fairseq2.data.VocabularyInfo": [[55, 5, 1, "", "bos_idx"], [55, 5, 1, "", "eos_idx"], [55, 5, 1, "", "pad_idx"], [55, 5, 1, "", "size"], [55, 5, 1, "", "unk_idx"]], "fairseq2.data.text": [[62, 1, 1, "", "LineEnding"], [63, 1, 1, "", "MultilingualTextTokenizer"], [64, 1, 1, "", "SentencePieceDecoder"], [65, 1, 1, "", "SentencePieceEncoder"], [66, 1, 1, "", "SentencePieceModel"], [67, 1, 1, "", "StrSplitter"], [68, 1, 1, "", "StrToIntConverter"], [69, 1, 1, "", "StrToTensorConverter"], [70, 1, 1, "", "TextTokenDecoder"], [71, 1, 1, "", "TextTokenEncoder"], [72, 1, 1, "", "TextTokenizer"], [61, 6, 1, "", "read_text"], [73, 6, 1, "", "vocabulary_from_sentencepiece"]], "fairseq2.data.text.LineEnding": [[62, 2, 1, "", "__iter__"]], "fairseq2.data.text.MultilingualTextTokenizer": [[63, 2, 1, "", "create_decoder"], [63, 2, 1, "", "create_encoder"]], "fairseq2.data.text.SentencePieceDecoder": [[64, 2, 1, "", "__call__"]], "fairseq2.data.text.SentencePieceEncoder": [[65, 2, 1, "", "__call__"], [65, 3, 1, "", "prefix_indices"], [65, 3, 1, "", "suffix_indices"]], "fairseq2.data.text.StrSplitter": [[67, 2, 1, "", "__call__"]], "fairseq2.data.text.StrToIntConverter": [[68, 2, 1, "", "__call__"]], "fairseq2.data.text.StrToTensorConverter": [[69, 2, 1, "", "__call__"]], "fairseq2.data.text.TextTokenDecoder": [[70, 2, 1, "", "__call__"]], "fairseq2.data.text.TextTokenEncoder": [[71, 2, 1, "", "__call__"], [71, 3, 1, "", "prefix_indices"], [71, 3, 1, "", "suffix_indices"]], "fairseq2.data.text.TextTokenizer": [[72, 2, 1, "", "create_decoder"], [72, 2, 1, "", "create_encoder"]], "fairseq2.gang": [[8, 1, 1, "", "Gang"]], "fairseq2.gang.Gang": [[8, 2, 1, "", "all_gather"], [8, 2, 1, "", "all_reduce"], [8, 2, 1, "", "as_process_group"], [8, 2, 1, "", "barrier"]], "fairseq2.nn": [[20, 1, 1, "", "Embedding"], [21, 1, 1, "", "IncrementalState"], [22, 1, 1, "", "IncrementalStateBag"], [23, 1, 1, "", "LearnedPositionEncoder"], [24, 1, 1, "", "Linear"], [25, 1, 1, "", "ModuleList"], [9, 1, 1, "", "PositionEncoder"], [10, 1, 1, "", "Projection"], [26, 1, 1, "", "RotaryEncoder"], [27, 1, 1, "", "SinusoidalPositionEncoder"], [28, 1, 1, "", "TiedProjection"]], "fairseq2.nn.Embedding": [[20, 2, 1, "", "forward"]], "fairseq2.nn.IncrementalState": [[21, 2, 1, "", "reorder"]], "fairseq2.nn.IncrementalStateBag": [[22, 2, 1, "", "get_state"], [22, 2, 1, "", "increment_step"], [22, 2, 1, "", "reorder"], [22, 2, 1, "", "set_state"]], "fairseq2.nn.LearnedPositionEncoder": [[23, 2, 1, "", "forward"], [23, 2, 1, "", "reset_parameters"]], "fairseq2.nn.Linear": [[24, 2, 1, "", "forward"], [24, 2, 1, "", "reset_parameters"]], "fairseq2.nn.ModuleList": [[25, 2, 1, "", "append"], [25, 2, 1, "", "drop_iter"], [25, 2, 1, "", "extend"], [25, 2, 1, "", "insert"]], "fairseq2.nn.PositionEncoder": [[9, 2, 1, "", "_do_forward"], [9, 2, 1, "", "forward"]], "fairseq2.nn.Projection": [[10, 2, 1, "", "forward"]], "fairseq2.nn.RotaryEncoder": [[26, 2, 1, "", "_do_forward"], [26, 2, 1, "", "forward"], [26, 2, 1, "", "reset_non_persistent_buffers"], [26, 2, 1, "", "reset_parameters"]], "fairseq2.nn.SinusoidalPositionEncoder": [[27, 2, 1, "", "forward"], [27, 2, 1, "", "reset_non_persistent_buffers"], [27, 2, 1, "", "reset_parameters"]], "fairseq2.nn.TiedProjection": [[28, 2, 1, "", "forward"]], "fairseq2.nn.transformer": [[29, 1, 1, "", "ALiBiAttentionMaskGenerator"], [11, 1, 1, "", "AttentionMaskGenerator"], [12, 1, 1, "", "AttentionWeightHook"], [30, 1, 1, "", "CausalAttentionMaskGenerator"], [13, 1, 1, "", "FeedForwardNetwork"], [14, 1, 1, "", "MultiheadAttention"], [31, 1, 1, "", "RelativePositionSDPA"], [15, 1, 1, "", "SDPA"], [32, 1, 1, "", "StandardFeedForwardNetwork"], [33, 1, 1, "", "StandardMultiheadAttention"], [34, 1, 1, "", "StandardTransformerDecoder"], [35, 1, 1, "", "StandardTransformerDecoderLayer"], [36, 1, 1, "", "StandardTransformerEncoder"], [37, 1, 1, "", "StandardTransformerEncoderLayer"], [38, 1, 1, "", "StoreAttentionWeights"], [16, 1, 1, "", "TransformerDecoder"], [17, 1, 1, "", "TransformerDecoderLayer"], [18, 1, 1, "", "TransformerEncoder"], [19, 1, 1, "", "TransformerEncoderLayer"], [74, 1, 1, "", "TransformerNormOrder"]], "fairseq2.nn.transformer.ALiBiAttentionMaskGenerator": [[29, 2, 1, "", "__call__"]], "fairseq2.nn.transformer.AttentionMaskGenerator": [[11, 2, 1, "", "__call__"]], "fairseq2.nn.transformer.AttentionWeightHook": [[12, 2, 1, "", "__call__"]], "fairseq2.nn.transformer.CausalAttentionMaskGenerator": [[30, 2, 1, "", "__call__"]], "fairseq2.nn.transformer.FeedForwardNetwork": [[13, 2, 1, "", "forward"]], "fairseq2.nn.transformer.MultiheadAttention": [[14, 2, 1, "", "_run_attn_weight_hooks"], [14, 2, 1, "", "forward"], [14, 2, 1, "", "register_attn_weight_hook"]], "fairseq2.nn.transformer.RelativePositionSDPA": [[31, 2, 1, "", "forward"], [31, 2, 1, "", "reset_parameters"]], "fairseq2.nn.transformer.SDPA": [[15, 2, 1, "", "forward"]], "fairseq2.nn.transformer.StandardFeedForwardNetwork": [[32, 2, 1, "", "forward"]], "fairseq2.nn.transformer.StandardMultiheadAttention": [[33, 2, 1, "", "_run_attn_weight_hooks"], [33, 2, 1, "", "forward"], [33, 2, 1, "", "register_attn_weight_hook"], [33, 2, 1, "", "reset_parameters"]], "fairseq2.nn.transformer.StandardTransformerDecoder": [[34, 2, 1, "", "forward"]], "fairseq2.nn.transformer.StandardTransformerDecoderLayer": [[35, 2, 1, "", "forward"], [35, 2, 1, "", "reset_parameters"]], "fairseq2.nn.transformer.StandardTransformerEncoder": [[36, 2, 1, "", "forward"]], "fairseq2.nn.transformer.StandardTransformerEncoderLayer": [[37, 2, 1, "", "forward"], [37, 2, 1, "", "reset_parameters"]], "fairseq2.nn.transformer.StoreAttentionWeights": [[38, 2, 1, "", "__call__"]], "fairseq2.nn.transformer.TransformerDecoder": [[16, 2, 1, "", "forward"]], "fairseq2.nn.transformer.TransformerDecoderLayer": [[17, 2, 1, "", "forward"]], "fairseq2.nn.transformer.TransformerEncoder": [[18, 2, 1, "", "forward"]], "fairseq2.nn.transformer.TransformerEncoderLayer": [[19, 2, 1, "", "forward"]], "fairseq2.nn.transformer.TransformerNormOrder": [[74, 5, 1, "", "POST"], [74, 5, 1, "", "PRE"], [74, 5, 1, "", "PRE_WITH_NORMFORMER"], [74, 2, 1, "", "__iter__"]], "fairseq2.nn.utils.mask": [[75, 6, 1, "", "to_float_mask"], [76, 6, 1, "", "to_padding_mask"]], "fairseq2.optim.lr_scheduler": [[39, 1, 1, "", "CosineAnnealingLR"], [40, 1, 1, "", "LRSchedulerBase"], [41, 1, 1, "", "MyleLR"], [42, 1, 1, "", "NoamLR"], [43, 1, 1, "", "PolynomialDecayLR"]], "fairseq2.optim.lr_scheduler.CosineAnnealingLR": [[39, 2, 1, "", "get_last_lr"], [39, 2, 1, "", "load_state_dict"], [39, 2, 1, "", "print_lr"], [39, 2, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.LRSchedulerBase": [[40, 2, 1, "", "get_last_lr"], [40, 2, 1, "", "load_state_dict"], [40, 2, 1, "", "print_lr"], [40, 2, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.MyleLR": [[41, 2, 1, "", "get_last_lr"], [41, 2, 1, "", "load_state_dict"], [41, 2, 1, "", "print_lr"], [41, 2, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.NoamLR": [[42, 2, 1, "", "get_last_lr"], [42, 2, 1, "", "load_state_dict"], [42, 2, 1, "", "print_lr"], [42, 2, 1, "", "state_dict"]], "fairseq2.optim.lr_scheduler.PolynomialDecayLR": [[43, 2, 1, "", "get_last_lr"], [43, 2, 1, "", "load_state_dict"], [43, 2, 1, "", "print_lr"], [43, 2, 1, "", "state_dict"]]}, "objtypes": {"0": "py:exception", "1": "py:class", "2": "py:method", "3": "py:property", "4": "py:data", "5": "py:attribute", "6": "py:function"}, "objnames": {"0": ["py", "exception", "Python exception"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "property", "Python property"], "4": ["py", "data", "Python data"], "5": ["py", "attribute", "Python attribute"], "6": ["py", "function", "Python function"]}, "titleterms": {"bibliographi": 0, "fairseq2": [1, 5, 44, 50, 53], "document": 1, "refer": 1, "misc": 1, "abc": [2, 3], "protocol": [2, 3], "all": 3, "class": [3, 4, 5], "enum": [3, 6], "function": [3, 7], "data": [5, 44, 50, 53], "column": 5, "syntax": 5, "public": 5, "us": 5, "api": 5, "text": 5, "gang": 8, "positionencod": 9, "project": 10, "attentionmaskgener": 11, "attentionweighthook": 12, "feedforwardnetwork": 13, "multiheadattent": 14, "sdpa": 15, "transformerdecod": 16, "transformerdecoderlay": 17, "transformerencod": 18, "transformerencoderlay": 19, "embed": 20, "incrementalst": 21, "incrementalstatebag": 22, "learnedpositionencod": 23, "linear": 24, "modulelist": 25, "rotaryencod": 26, "sinusoidalpositionencod": 27, "tiedproject": 28, "alibiattentionmaskgener": 29, "causalattentionmaskgener": 30, "relativepositionsdpa": 31, "standardfeedforwardnetwork": 32, "standardmultiheadattent": 33, "standardtransformerdecod": 34, "standardtransformerdecoderlay": 35, "standardtransformerencod": 36, "standardtransformerencoderlay": 37, "storeattentionweight": 38, "cosineannealinglr": 39, "lrschedulerbas": 40, "mylelr": 41, "noamlr": 42, "polynomialdecaylr": 43, "bytestreamerror": 44, "cstring": 45, "collateoptionsoverrid": 46, "collat": 47, "datapipelin": 48, "datapipelinebuild": 49, "datapipelineerror": 50, "filemapp": 51, "pathlik": 52, "recorderror": 53, "stringlik": 54, "vocabularyinfo": 55, "get_last_failed_exampl": 56, "is_string_lik": 57, "list_fil": 58, "read_sequ": 59, "read_zipped_record": 60, "read_text": 61, "lineend": 62, "multilingualtexttoken": 63, "sentencepiecedecod": 64, "sentencepieceencod": 65, "sentencepiecemodel": 66, "strsplitter": 67, "strtointconvert": 68, "strtotensorconvert": 69, "texttokendecod": 70, "texttokenencod": 71, "texttoken": 72, "vocabulary_from_sentencepiec": 73, "transformernormord": 74, "to_float_mask": 75, "to_padding_mask": 76}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9, "sphinx": 57}, "alltitles": {"Bibliography": [[0, "bibliography"]], "fairseq2 documentation": [[1, "fairseq2-documentation"]], "fairseq2 Reference": [[1, null]], "Misc": [[1, null]], "ABCs and Protocols": [[2, "abcs-and-protocols"], [3, "abcs-and-protocols"]], "All": [[3, "all"]], "Classes": [[3, "classes"], [4, "classes"]], "Enums": [[3, "enums"], [6, "enums"]], "Functions": [[3, "functions"], [7, "functions"]], "fairseq2.data": [[5, "fairseq2-data"]], "Column syntax": [[5, "column-syntax"]], "Public classes used in fairseq2 API:": [[5, "public-classes-used-in-fairseq2-api"]], "fairseq2.data.text": [[5, "fairseq2-data-text"]], "Gang": [[8, "gang"]], "PositionEncoder": [[9, "positionencoder"]], "Projection": [[10, "projection"]], "AttentionMaskGenerator": [[11, "attentionmaskgenerator"]], "AttentionWeightHook": [[12, "attentionweighthook"]], "FeedForwardNetwork": [[13, "feedforwardnetwork"]], "MultiheadAttention": [[14, "multiheadattention"]], "SDPA": [[15, "sdpa"]], "TransformerDecoder": [[16, "transformerdecoder"]], "TransformerDecoderLayer": [[17, "transformerdecoderlayer"]], "TransformerEncoder": [[18, "transformerencoder"]], "TransformerEncoderLayer": [[19, "transformerencoderlayer"]], "Embedding": [[20, "embedding"]], "IncrementalState": [[21, "incrementalstate"]], "IncrementalStateBag": [[22, "incrementalstatebag"]], "LearnedPositionEncoder": [[23, "learnedpositionencoder"]], "Linear": [[24, "linear"]], "ModuleList": [[25, "modulelist"]], "RotaryEncoder": [[26, "rotaryencoder"]], "SinusoidalPositionEncoder": [[27, "sinusoidalpositionencoder"]], "TiedProjection": [[28, "tiedprojection"]], "ALiBiAttentionMaskGenerator": [[29, "alibiattentionmaskgenerator"]], "CausalAttentionMaskGenerator": [[30, "causalattentionmaskgenerator"]], "RelativePositionSDPA": [[31, "relativepositionsdpa"]], "StandardFeedForwardNetwork": [[32, "standardfeedforwardnetwork"]], "StandardMultiheadAttention": [[33, "standardmultiheadattention"]], "StandardTransformerDecoder": [[34, "standardtransformerdecoder"]], "StandardTransformerDecoderLayer": [[35, "standardtransformerdecoderlayer"]], "StandardTransformerEncoder": [[36, "standardtransformerencoder"]], "StandardTransformerEncoderLayer": [[37, "standardtransformerencoderlayer"]], "StoreAttentionWeights": [[38, "storeattentionweights"]], "CosineAnnealingLR": [[39, "cosineannealinglr"]], "LRSchedulerBase": [[40, "lrschedulerbase"]], "MyleLR": [[41, "mylelr"]], "NoamLR": [[42, "noamlr"]], "PolynomialDecayLR": [[43, "polynomialdecaylr"]], "fairseq2.data.ByteStreamError": [[44, "fairseq2-data-bytestreamerror"]], "CString": [[45, "cstring"]], "CollateOptionsOverride": [[46, "collateoptionsoverride"]], "Collater": [[47, "collater"]], "DataPipeline": [[48, "datapipeline"]], "DataPipelineBuilder": [[49, "datapipelinebuilder"]], "fairseq2.data.DataPipelineError": [[50, "fairseq2-data-datapipelineerror"]], "FileMapper": [[51, "filemapper"]], "PathLike": [[52, "pathlike"]], "fairseq2.data.RecordError": [[53, "fairseq2-data-recorderror"]], "StringLike": [[54, "stringlike"]], "VocabularyInfo": [[55, "vocabularyinfo"]], "get_last_failed_example": [[56, "get-last-failed-example"]], "is_string_like": [[57, "is-string-like"]], "list_files": [[58, "list-files"]], "read_sequence": [[59, "read-sequence"]], "read_zipped_records": [[60, "read-zipped-records"]], "read_text": [[61, "read-text"]], "LineEnding": [[62, "lineending"]], "MultilingualTextTokenizer": [[63, "multilingualtexttokenizer"]], "SentencePieceDecoder": [[64, "sentencepiecedecoder"]], "SentencePieceEncoder": [[65, "sentencepieceencoder"]], "SentencePieceModel": [[66, "sentencepiecemodel"]], "StrSplitter": [[67, "strsplitter"]], "StrToIntConverter": [[68, "strtointconverter"]], "StrToTensorConverter": [[69, "strtotensorconverter"]], "TextTokenDecoder": [[70, "texttokendecoder"]], "TextTokenEncoder": [[71, "texttokenencoder"]], "TextTokenizer": [[72, "texttokenizer"]], "vocabulary_from_sentencepiece": [[73, "vocabulary-from-sentencepiece"]], "TransformerNormOrder": [[74, "transformernormorder"]], "to_float_mask": [[75, "to-float-mask"]], "to_padding_mask": [[76, "to-padding-mask"]]}, "indexentries": {"gang (class in fairseq2.gang)": [[8, "fairseq2.gang.Gang"]], "all_gather() (fairseq2.gang.gang method)": [[8, "fairseq2.gang.Gang.all_gather"]], "all_reduce() (fairseq2.gang.gang method)": [[8, "fairseq2.gang.Gang.all_reduce"]], "as_process_group() (fairseq2.gang.gang method)": [[8, "fairseq2.gang.Gang.as_process_group"]], "barrier() (fairseq2.gang.gang method)": [[8, "fairseq2.gang.Gang.barrier"]], "positionencoder (class in fairseq2.nn)": [[9, "fairseq2.nn.PositionEncoder"]], "_do_forward() (fairseq2.nn.positionencoder method)": [[9, "fairseq2.nn.PositionEncoder._do_forward"]], "forward() (fairseq2.nn.positionencoder method)": [[9, "fairseq2.nn.PositionEncoder.forward"]], "projection (class in fairseq2.nn)": [[10, "fairseq2.nn.Projection"]], "forward() (fairseq2.nn.projection method)": [[10, "fairseq2.nn.Projection.forward"]], "attentionmaskgenerator (class in fairseq2.nn.transformer)": [[11, "fairseq2.nn.transformer.AttentionMaskGenerator"]], "__call__() (fairseq2.nn.transformer.attentionmaskgenerator method)": [[11, "fairseq2.nn.transformer.AttentionMaskGenerator.__call__"]], "attentionweighthook (class in fairseq2.nn.transformer)": [[12, "fairseq2.nn.transformer.AttentionWeightHook"]], "__call__() (fairseq2.nn.transformer.attentionweighthook method)": [[12, "fairseq2.nn.transformer.AttentionWeightHook.__call__"]], "feedforwardnetwork (class in fairseq2.nn.transformer)": [[13, "fairseq2.nn.transformer.FeedForwardNetwork"]], "forward() (fairseq2.nn.transformer.feedforwardnetwork method)": [[13, "fairseq2.nn.transformer.FeedForwardNetwork.forward"]], "multiheadattention (class in fairseq2.nn.transformer)": [[14, "fairseq2.nn.transformer.MultiheadAttention"]], "_run_attn_weight_hooks() (fairseq2.nn.transformer.multiheadattention method)": [[14, "fairseq2.nn.transformer.MultiheadAttention._run_attn_weight_hooks"]], "forward() (fairseq2.nn.transformer.multiheadattention method)": [[14, "fairseq2.nn.transformer.MultiheadAttention.forward"]], "register_attn_weight_hook() (fairseq2.nn.transformer.multiheadattention method)": [[14, "fairseq2.nn.transformer.MultiheadAttention.register_attn_weight_hook"]], "sdpa (class in fairseq2.nn.transformer)": [[15, "fairseq2.nn.transformer.SDPA"]], "forward() (fairseq2.nn.transformer.sdpa method)": [[15, "fairseq2.nn.transformer.SDPA.forward"]], "transformerdecoder (class in fairseq2.nn.transformer)": [[16, "fairseq2.nn.transformer.TransformerDecoder"]], "forward() (fairseq2.nn.transformer.transformerdecoder method)": [[16, "fairseq2.nn.transformer.TransformerDecoder.forward"]], "transformerdecoderlayer (class in fairseq2.nn.transformer)": [[17, "fairseq2.nn.transformer.TransformerDecoderLayer"]], "forward() (fairseq2.nn.transformer.transformerdecoderlayer method)": [[17, "fairseq2.nn.transformer.TransformerDecoderLayer.forward"]], "transformerencoder (class in fairseq2.nn.transformer)": [[18, "fairseq2.nn.transformer.TransformerEncoder"]], "forward() (fairseq2.nn.transformer.transformerencoder method)": [[18, "fairseq2.nn.transformer.TransformerEncoder.forward"]], "transformerencoderlayer (class in fairseq2.nn.transformer)": [[19, "fairseq2.nn.transformer.TransformerEncoderLayer"]], "forward() (fairseq2.nn.transformer.transformerencoderlayer method)": [[19, "fairseq2.nn.transformer.TransformerEncoderLayer.forward"]], "embedding (class in fairseq2.nn)": [[20, "fairseq2.nn.Embedding"]], "forward() (fairseq2.nn.embedding method)": [[20, "fairseq2.nn.Embedding.forward"]], "incrementalstate (class in fairseq2.nn)": [[21, "fairseq2.nn.IncrementalState"]], "reorder() (fairseq2.nn.incrementalstate method)": [[21, "fairseq2.nn.IncrementalState.reorder"]], "incrementalstatebag (class in fairseq2.nn)": [[22, "fairseq2.nn.IncrementalStateBag"]], "get_state() (fairseq2.nn.incrementalstatebag method)": [[22, "fairseq2.nn.IncrementalStateBag.get_state"]], "increment_step() (fairseq2.nn.incrementalstatebag method)": [[22, "fairseq2.nn.IncrementalStateBag.increment_step"]], "reorder() (fairseq2.nn.incrementalstatebag method)": [[22, "fairseq2.nn.IncrementalStateBag.reorder"]], "set_state() (fairseq2.nn.incrementalstatebag method)": [[22, "fairseq2.nn.IncrementalStateBag.set_state"]], "learnedpositionencoder (class in fairseq2.nn)": [[23, "fairseq2.nn.LearnedPositionEncoder"]], "forward() (fairseq2.nn.learnedpositionencoder method)": [[23, "fairseq2.nn.LearnedPositionEncoder.forward"]], "reset_parameters() (fairseq2.nn.learnedpositionencoder method)": [[23, "fairseq2.nn.LearnedPositionEncoder.reset_parameters"]], "linear (class in fairseq2.nn)": [[24, "fairseq2.nn.Linear"]], "forward() (fairseq2.nn.linear method)": [[24, "fairseq2.nn.Linear.forward"]], "reset_parameters() (fairseq2.nn.linear method)": [[24, "fairseq2.nn.Linear.reset_parameters"]], "modulelist (class in fairseq2.nn)": [[25, "fairseq2.nn.ModuleList"]], "append() (fairseq2.nn.modulelist method)": [[25, "fairseq2.nn.ModuleList.append"]], "drop_iter() (fairseq2.nn.modulelist method)": [[25, "fairseq2.nn.ModuleList.drop_iter"]], "extend() (fairseq2.nn.modulelist method)": [[25, "fairseq2.nn.ModuleList.extend"]], "insert() (fairseq2.nn.modulelist method)": [[25, "fairseq2.nn.ModuleList.insert"]], "rotaryencoder (class in fairseq2.nn)": [[26, "fairseq2.nn.RotaryEncoder"]], "_do_forward() (fairseq2.nn.rotaryencoder method)": [[26, "fairseq2.nn.RotaryEncoder._do_forward"]], "forward() (fairseq2.nn.rotaryencoder method)": [[26, "fairseq2.nn.RotaryEncoder.forward"]], "reset_non_persistent_buffers() (fairseq2.nn.rotaryencoder method)": [[26, "fairseq2.nn.RotaryEncoder.reset_non_persistent_buffers"]], "reset_parameters() (fairseq2.nn.rotaryencoder method)": [[26, "fairseq2.nn.RotaryEncoder.reset_parameters"]], "sinusoidalpositionencoder (class in fairseq2.nn)": [[27, "fairseq2.nn.SinusoidalPositionEncoder"]], "forward() (fairseq2.nn.sinusoidalpositionencoder method)": [[27, "fairseq2.nn.SinusoidalPositionEncoder.forward"]], "reset_non_persistent_buffers() (fairseq2.nn.sinusoidalpositionencoder method)": [[27, "fairseq2.nn.SinusoidalPositionEncoder.reset_non_persistent_buffers"]], "reset_parameters() (fairseq2.nn.sinusoidalpositionencoder method)": [[27, "fairseq2.nn.SinusoidalPositionEncoder.reset_parameters"]], "tiedprojection (class in fairseq2.nn)": [[28, "fairseq2.nn.TiedProjection"]], "forward() (fairseq2.nn.tiedprojection method)": [[28, "fairseq2.nn.TiedProjection.forward"]], "alibiattentionmaskgenerator (class in fairseq2.nn.transformer)": [[29, "fairseq2.nn.transformer.ALiBiAttentionMaskGenerator"]], "__call__() (fairseq2.nn.transformer.alibiattentionmaskgenerator method)": [[29, "fairseq2.nn.transformer.ALiBiAttentionMaskGenerator.__call__"]], "causalattentionmaskgenerator (class in fairseq2.nn.transformer)": [[30, "fairseq2.nn.transformer.CausalAttentionMaskGenerator"]], "__call__() (fairseq2.nn.transformer.causalattentionmaskgenerator method)": [[30, "fairseq2.nn.transformer.CausalAttentionMaskGenerator.__call__"]], "relativepositionsdpa (class in fairseq2.nn.transformer)": [[31, "fairseq2.nn.transformer.RelativePositionSDPA"]], "forward() (fairseq2.nn.transformer.relativepositionsdpa method)": [[31, "fairseq2.nn.transformer.RelativePositionSDPA.forward"]], "reset_parameters() (fairseq2.nn.transformer.relativepositionsdpa method)": [[31, "fairseq2.nn.transformer.RelativePositionSDPA.reset_parameters"]], "standardfeedforwardnetwork (class in fairseq2.nn.transformer)": [[32, "fairseq2.nn.transformer.StandardFeedForwardNetwork"]], "forward() (fairseq2.nn.transformer.standardfeedforwardnetwork method)": [[32, "fairseq2.nn.transformer.StandardFeedForwardNetwork.forward"]], "standardmultiheadattention (class in fairseq2.nn.transformer)": [[33, "fairseq2.nn.transformer.StandardMultiheadAttention"]], "_run_attn_weight_hooks() (fairseq2.nn.transformer.standardmultiheadattention method)": [[33, "fairseq2.nn.transformer.StandardMultiheadAttention._run_attn_weight_hooks"]], "forward() (fairseq2.nn.transformer.standardmultiheadattention method)": [[33, "fairseq2.nn.transformer.StandardMultiheadAttention.forward"]], "register_attn_weight_hook() (fairseq2.nn.transformer.standardmultiheadattention method)": [[33, "fairseq2.nn.transformer.StandardMultiheadAttention.register_attn_weight_hook"]], "reset_parameters() (fairseq2.nn.transformer.standardmultiheadattention method)": [[33, "fairseq2.nn.transformer.StandardMultiheadAttention.reset_parameters"]], "standardtransformerdecoder (class in fairseq2.nn.transformer)": [[34, "fairseq2.nn.transformer.StandardTransformerDecoder"]], "forward() (fairseq2.nn.transformer.standardtransformerdecoder method)": [[34, "fairseq2.nn.transformer.StandardTransformerDecoder.forward"]], "standardtransformerdecoderlayer (class in fairseq2.nn.transformer)": [[35, "fairseq2.nn.transformer.StandardTransformerDecoderLayer"]], "forward() (fairseq2.nn.transformer.standardtransformerdecoderlayer method)": [[35, "fairseq2.nn.transformer.StandardTransformerDecoderLayer.forward"]], "reset_parameters() (fairseq2.nn.transformer.standardtransformerdecoderlayer method)": [[35, "fairseq2.nn.transformer.StandardTransformerDecoderLayer.reset_parameters"]], "standardtransformerencoder (class in fairseq2.nn.transformer)": [[36, "fairseq2.nn.transformer.StandardTransformerEncoder"]], "forward() (fairseq2.nn.transformer.standardtransformerencoder method)": [[36, "fairseq2.nn.transformer.StandardTransformerEncoder.forward"]], "standardtransformerencoderlayer (class in fairseq2.nn.transformer)": [[37, "fairseq2.nn.transformer.StandardTransformerEncoderLayer"]], "forward() (fairseq2.nn.transformer.standardtransformerencoderlayer method)": [[37, "fairseq2.nn.transformer.StandardTransformerEncoderLayer.forward"]], "reset_parameters() (fairseq2.nn.transformer.standardtransformerencoderlayer method)": [[37, "fairseq2.nn.transformer.StandardTransformerEncoderLayer.reset_parameters"]], "storeattentionweights (class in fairseq2.nn.transformer)": [[38, "fairseq2.nn.transformer.StoreAttentionWeights"]], "__call__() (fairseq2.nn.transformer.storeattentionweights method)": [[38, "fairseq2.nn.transformer.StoreAttentionWeights.__call__"]], "cosineannealinglr (class in fairseq2.optim.lr_scheduler)": [[39, "fairseq2.optim.lr_scheduler.CosineAnnealingLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[39, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[39, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[39, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.cosineannealinglr method)": [[39, "fairseq2.optim.lr_scheduler.CosineAnnealingLR.state_dict"]], "lrschedulerbase (class in fairseq2.optim.lr_scheduler)": [[40, "fairseq2.optim.lr_scheduler.LRSchedulerBase"]], "get_last_lr() (fairseq2.optim.lr_scheduler.lrschedulerbase method)": [[40, "fairseq2.optim.lr_scheduler.LRSchedulerBase.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.lrschedulerbase method)": [[40, "fairseq2.optim.lr_scheduler.LRSchedulerBase.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.lrschedulerbase method)": [[40, "fairseq2.optim.lr_scheduler.LRSchedulerBase.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.lrschedulerbase method)": [[40, "fairseq2.optim.lr_scheduler.LRSchedulerBase.state_dict"]], "mylelr (class in fairseq2.optim.lr_scheduler)": [[41, "fairseq2.optim.lr_scheduler.MyleLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.mylelr method)": [[41, "fairseq2.optim.lr_scheduler.MyleLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.mylelr method)": [[41, "fairseq2.optim.lr_scheduler.MyleLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.mylelr method)": [[41, "fairseq2.optim.lr_scheduler.MyleLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.mylelr method)": [[41, "fairseq2.optim.lr_scheduler.MyleLR.state_dict"]], "noamlr (class in fairseq2.optim.lr_scheduler)": [[42, "fairseq2.optim.lr_scheduler.NoamLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.noamlr method)": [[42, "fairseq2.optim.lr_scheduler.NoamLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.noamlr method)": [[42, "fairseq2.optim.lr_scheduler.NoamLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.noamlr method)": [[42, "fairseq2.optim.lr_scheduler.NoamLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.noamlr method)": [[42, "fairseq2.optim.lr_scheduler.NoamLR.state_dict"]], "polynomialdecaylr (class in fairseq2.optim.lr_scheduler)": [[43, "fairseq2.optim.lr_scheduler.PolynomialDecayLR"]], "get_last_lr() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[43, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.get_last_lr"]], "load_state_dict() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[43, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.load_state_dict"]], "print_lr() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[43, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.print_lr"]], "state_dict() (fairseq2.optim.lr_scheduler.polynomialdecaylr method)": [[43, "fairseq2.optim.lr_scheduler.PolynomialDecayLR.state_dict"]], "bytestreamerror": [[44, "fairseq2.data.ByteStreamError"]], "cstring (class in fairseq2.data)": [[45, "fairseq2.data.CString"]], "bytes() (fairseq2.data.cstring method)": [[45, "fairseq2.data.CString.bytes"]], "lstrip() (fairseq2.data.cstring method)": [[45, "fairseq2.data.CString.lstrip"]], "rstrip() (fairseq2.data.cstring method)": [[45, "fairseq2.data.CString.rstrip"]], "split() (fairseq2.data.cstring method)": [[45, "fairseq2.data.CString.split"]], "collateoptionsoverride (class in fairseq2.data)": [[46, "fairseq2.data.CollateOptionsOverride"]], "collater (class in fairseq2.data)": [[47, "fairseq2.data.Collater"]], "__call__() (fairseq2.data.collater method)": [[47, "fairseq2.data.Collater.__call__"]], "datapipeline (class in fairseq2.data)": [[48, "fairseq2.data.DataPipeline"]], "__iter__() (fairseq2.data.datapipeline method)": [[48, "fairseq2.data.DataPipeline.__iter__"]], "is_broken (fairseq2.data.datapipeline property)": [[48, "fairseq2.data.DataPipeline.is_broken"]], "load_state_dict() (fairseq2.data.datapipeline method)": [[48, "fairseq2.data.DataPipeline.load_state_dict"]], "reset() (fairseq2.data.datapipeline method)": [[48, "fairseq2.data.DataPipeline.reset"]], "round_robin() (fairseq2.data.datapipeline static method)": [[48, "fairseq2.data.DataPipeline.round_robin"]], "sample() (fairseq2.data.datapipeline static method)": [[48, "fairseq2.data.DataPipeline.sample"]], "state_dict() (fairseq2.data.datapipeline method)": [[48, "fairseq2.data.DataPipeline.state_dict"]], "zip() (fairseq2.data.datapipeline static method)": [[48, "fairseq2.data.DataPipeline.zip"]], "datapipelinebuilder (class in fairseq2.data)": [[49, "fairseq2.data.DataPipelineBuilder"]], "and_return() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.and_return"]], "bucket() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.bucket"]], "bucket_by_length() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.bucket_by_length"]], "filter() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.filter"]], "map() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.map"]], "prefetch() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.prefetch"]], "shard() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.shard"]], "shuffle() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.shuffle"]], "skip() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.skip"]], "take() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.take"]], "yield_from() (fairseq2.data.datapipelinebuilder method)": [[49, "fairseq2.data.DataPipelineBuilder.yield_from"]], "datapipelineerror": [[50, "fairseq2.data.DataPipelineError"]], "filemapper (class in fairseq2.data)": [[51, "fairseq2.data.FileMapper"]], "__call__() (fairseq2.data.filemapper method)": [[51, "fairseq2.data.FileMapper.__call__"]], "pathlike (in module fairseq2.data)": [[52, "fairseq2.data.PathLike"]], "recorderror": [[53, "fairseq2.data.RecordError"]], "stringlike (in module fairseq2.data)": [[54, "fairseq2.data.StringLike"]], "vocabularyinfo (class in fairseq2.data)": [[55, "fairseq2.data.VocabularyInfo"]], "bos_idx (fairseq2.data.vocabularyinfo attribute)": [[55, "fairseq2.data.VocabularyInfo.bos_idx"]], "eos_idx (fairseq2.data.vocabularyinfo attribute)": [[55, "fairseq2.data.VocabularyInfo.eos_idx"]], "pad_idx (fairseq2.data.vocabularyinfo attribute)": [[55, "fairseq2.data.VocabularyInfo.pad_idx"]], "size (fairseq2.data.vocabularyinfo attribute)": [[55, "fairseq2.data.VocabularyInfo.size"]], "unk_idx (fairseq2.data.vocabularyinfo attribute)": [[55, "fairseq2.data.VocabularyInfo.unk_idx"]], "get_last_failed_example() (in module fairseq2.data)": [[56, "fairseq2.data.get_last_failed_example"]], "is_string_like() (in module fairseq2.data)": [[57, "fairseq2.data.is_string_like"]], "list_files() (in module fairseq2.data)": [[58, "fairseq2.data.list_files"]], "read_sequence() (in module fairseq2.data)": [[59, "fairseq2.data.read_sequence"]], "read_zipped_records() (in module fairseq2.data)": [[60, "fairseq2.data.read_zipped_records"]], "read_text() (in module fairseq2.data.text)": [[61, "fairseq2.data.text.read_text"]], "lineending (class in fairseq2.data.text)": [[62, "fairseq2.data.text.LineEnding"]], "__iter__() (fairseq2.data.text.lineending class method)": [[62, "fairseq2.data.text.LineEnding.__iter__"]], "multilingualtexttokenizer (class in fairseq2.data.text)": [[63, "fairseq2.data.text.MultilingualTextTokenizer"]], "create_decoder() (fairseq2.data.text.multilingualtexttokenizer method)": [[63, "fairseq2.data.text.MultilingualTextTokenizer.create_decoder"]], "create_encoder() (fairseq2.data.text.multilingualtexttokenizer method)": [[63, "fairseq2.data.text.MultilingualTextTokenizer.create_encoder"]], "sentencepiecedecoder (class in fairseq2.data.text)": [[64, "fairseq2.data.text.SentencePieceDecoder"]], "__call__() (fairseq2.data.text.sentencepiecedecoder method)": [[64, "fairseq2.data.text.SentencePieceDecoder.__call__"]], "sentencepieceencoder (class in fairseq2.data.text)": [[65, "fairseq2.data.text.SentencePieceEncoder"]], "__call__() (fairseq2.data.text.sentencepieceencoder method)": [[65, "fairseq2.data.text.SentencePieceEncoder.__call__"]], "prefix_indices (fairseq2.data.text.sentencepieceencoder property)": [[65, "fairseq2.data.text.SentencePieceEncoder.prefix_indices"]], "suffix_indices (fairseq2.data.text.sentencepieceencoder property)": [[65, "fairseq2.data.text.SentencePieceEncoder.suffix_indices"]], "sentencepiecemodel (class in fairseq2.data.text)": [[66, "fairseq2.data.text.SentencePieceModel"]], "strsplitter (class in fairseq2.data.text)": [[67, "fairseq2.data.text.StrSplitter"]], "__call__() (fairseq2.data.text.strsplitter method)": [[67, "fairseq2.data.text.StrSplitter.__call__"]], "strtointconverter (class in fairseq2.data.text)": [[68, "fairseq2.data.text.StrToIntConverter"]], "__call__() (fairseq2.data.text.strtointconverter method)": [[68, "fairseq2.data.text.StrToIntConverter.__call__"]], "strtotensorconverter (class in fairseq2.data.text)": [[69, "fairseq2.data.text.StrToTensorConverter"]], "__call__() (fairseq2.data.text.strtotensorconverter method)": [[69, "fairseq2.data.text.StrToTensorConverter.__call__"]], "texttokendecoder (class in fairseq2.data.text)": [[70, "fairseq2.data.text.TextTokenDecoder"]], "__call__() (fairseq2.data.text.texttokendecoder method)": [[70, "fairseq2.data.text.TextTokenDecoder.__call__"]], "texttokenencoder (class in fairseq2.data.text)": [[71, "fairseq2.data.text.TextTokenEncoder"]], "__call__() (fairseq2.data.text.texttokenencoder method)": [[71, "fairseq2.data.text.TextTokenEncoder.__call__"]], "prefix_indices (fairseq2.data.text.texttokenencoder property)": [[71, "fairseq2.data.text.TextTokenEncoder.prefix_indices"]], "suffix_indices (fairseq2.data.text.texttokenencoder property)": [[71, "fairseq2.data.text.TextTokenEncoder.suffix_indices"]], "texttokenizer (class in fairseq2.data.text)": [[72, "fairseq2.data.text.TextTokenizer"]], "create_decoder() (fairseq2.data.text.texttokenizer method)": [[72, "fairseq2.data.text.TextTokenizer.create_decoder"]], "create_encoder() (fairseq2.data.text.texttokenizer method)": [[72, "fairseq2.data.text.TextTokenizer.create_encoder"]], "vocabulary_from_sentencepiece() (in module fairseq2.data.text)": [[73, "fairseq2.data.text.vocabulary_from_sentencepiece"]], "post (fairseq2.nn.transformer.transformernormorder attribute)": [[74, "fairseq2.nn.transformer.TransformerNormOrder.POST"]], "pre (fairseq2.nn.transformer.transformernormorder attribute)": [[74, "fairseq2.nn.transformer.TransformerNormOrder.PRE"]], "pre_with_normformer (fairseq2.nn.transformer.transformernormorder attribute)": [[74, "fairseq2.nn.transformer.TransformerNormOrder.PRE_WITH_NORMFORMER"]], "transformernormorder (class in fairseq2.nn.transformer)": [[74, "fairseq2.nn.transformer.TransformerNormOrder"]], "__iter__() (fairseq2.nn.transformer.transformernormorder class method)": [[74, "fairseq2.nn.transformer.TransformerNormOrder.__iter__"]], "to_float_mask() (in module fairseq2.nn.utils.mask)": [[75, "fairseq2.nn.utils.mask.to_float_mask"]], "to_padding_mask() (in module fairseq2.nn.utils.mask)": [[76, "fairseq2.nn.utils.mask.to_padding_mask"]]}})